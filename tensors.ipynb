{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ae3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d10464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 dimensions for each word\n",
    "import math\n",
    "def positionalEncodings(sequence):\n",
    "    \n",
    "    PE=[]\n",
    "    d_model=4\n",
    "    for pos in range(sequence):\n",
    "        EncodingsOfEach=[]\n",
    "        for i in range(d_model):\n",
    "            if i%2==0:\n",
    "                temp=pos/(math.pow(10000,(2*i)/d_model))\n",
    "                EncodingsOfEach.append(math.sin(temp))\n",
    "            else:\n",
    "                temp=pos/(math.pow(10000,(2*(i-1))/d_model))\n",
    "                EncodingsOfEach.append(math.cos(temp))\n",
    "        PE.append(EncodingsOfEach)\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fff696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfAttention(embeddings, W_q, W_k, W_v):\n",
    "    numberOfWords = tf.shape(embeddings)[0]\n",
    "\n",
    "    Q, K, V = [], [], []\n",
    "    for i in range(numberOfWords):\n",
    "        x_i = tf.expand_dims(embeddings[i], 0)\n",
    "        Q.append(tf.matmul(x_i, W_q))\n",
    "        K.append(tf.matmul(x_i, W_k))\n",
    "        V.append(tf.matmul(x_i, W_v))\n",
    "\n",
    "    d_k = tf.math.sqrt(tf.cast(tf.shape(K[0])[1], tf.float32))\n",
    "\n",
    "    attention_outputs = []\n",
    "\n",
    "    for i in range(numberOfWords):\n",
    "        score_list = []\n",
    "        for j in range(numberOfWords):\n",
    "            score = tf.matmul(Q[i], K[j], transpose_b=True)[0, 0] / d_k\n",
    "            score_list.append(score)\n",
    "\n",
    "        scores = tf.stack(score_list)\n",
    "        weights = tf.nn.softmax(scores)\n",
    "\n",
    "        output = tf.zeros_like(V[0])\n",
    "        for j in range(numberOfWords):\n",
    "            output += weights[j] * V[j]\n",
    "\n",
    "        attention_outputs.append(output[0])\n",
    "\n",
    "    return tf.stack(attention_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adc88dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_and_normalize(output_of_previous,input_of_previous):\n",
    "    layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    return layer_norm(output_of_previous + input_of_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea40a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeedForwardNN(x, W1, b1, W2, b2):\n",
    "    hidden = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "    out = tf.matmul(hidden, W2) + b2\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5f8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(positional_encodings_plus_embeddings,W_q,W_k,W_v,W1,b1,W2,b2):\n",
    "    self_attn_output=selfAttention(positional_encodings_plus_embeddings,W_q,W_k,W_v)\n",
    "    add_and_normalize_1_output=Add_and_normalize(self_attn_output,positional_encodings_plus_embeddings)\n",
    "    ffn_output=FeedForwardNN(add_and_normalize_1_output,W1,b1,W2,b2)\n",
    "    encoder_output=Add_and_normalize(ffn_output,add_and_normalize_1_output)\n",
    "    return encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ae8bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=tf.constant([[1,0,1,0],[0,1,0,1],[1,1,1,1]],dtype=tf.float32)\n",
    "positional_encodings=positionalEncodings(len(embeddings))\n",
    "embeddings_plus_PE=embeddings+positional_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2b616c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=embeddings_plus_PE[0].shape[0]\n",
    "W_q=tf.constant([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],dtype=tf.float32)\n",
    "W_k=tf.constant([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],dtype=tf.float32)\n",
    "W_v=tf.constant([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],dtype=tf.float32)\n",
    "W1 = tf.random.normal(shape=(d_model,256))\n",
    "b1 = tf.random.normal(shape=(256,))\n",
    "W2 = tf.random.normal(shape=(256,d_model))\n",
    "b2 = tf.random.normal(shape=(d_model,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ba508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.7105796   1.3845652  -1.1588589   0.48487327]\n",
      " [-0.83903754  1.3066386  -1.0938545   0.6262537 ]\n",
      " [-0.6768905   1.4612029  -1.1334834   0.34917092]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(Encoder(embeddings_plus_PE,W_q,W_k,W_v,W1,b1,W2,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c708cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=embeddings_plus_PE[0].shape[0]\n",
    "encoder_params = []\n",
    "for _ in range(6):\n",
    "    params = {\n",
    "        \"W_q\": tf.random.normal(shape=(d_model,d_model)),\n",
    "        \"W_k\": tf.random.normal(shape=(d_model,d_model)),\n",
    "        \"W_v\": tf.random.normal(shape=(d_model,d_model)),\n",
    "        \"W1\": tf.random.normal(shape=(d_model,256)),\n",
    "        \"b1\": tf.random.normal(shape=(256,)),\n",
    "        \"W2\": tf.random.normal(shape=(256,d_model)),\n",
    "        \"b2\": tf.random.normal(shape=(d_model,))\n",
    "    }\n",
    "    encoder_params.append(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e386143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoderStack(x, encoder_params):\n",
    "    for layer in encoder_params:\n",
    "        x = Encoder(\n",
    "            x,\n",
    "            layer[\"W_q\"],\n",
    "            layer[\"W_k\"],\n",
    "            layer[\"W_v\"],\n",
    "            layer[\"W1\"],\n",
    "            layer[\"b1\"],\n",
    "            layer[\"W2\"],\n",
    "            layer[\"b2\"]\n",
    "        )\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1364aedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.42652076 -0.81188786 -1.0492232   1.4345901 ]\n",
      " [ 0.38801178 -0.8178501  -1.0276964   1.4575348 ]\n",
      " [ 0.44736645 -0.8075728  -1.0614312   1.4216375 ]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(encoderStack(embeddings_plus_PE,encoder_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8df09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnnProject2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
