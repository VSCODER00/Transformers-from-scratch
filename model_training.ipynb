{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8130f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0518e5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>User Utterance</th>\n",
       "      <th>Bot Response</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Context/Session ID</th>\n",
       "      <th>Entities</th>\n",
       "      <th>User Feedback</th>\n",
       "      <th>Conversation Outcome</th>\n",
       "      <th>User Profile</th>\n",
       "      <th>Channel/Platform</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Emotion/Sentiment</th>\n",
       "      <th>Location</th>\n",
       "      <th>User Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uKqYhMMQ5S</td>\n",
       "      <td>Charge bar between follow student.</td>\n",
       "      <td>Important law into large example range. Player...</td>\n",
       "      <td>2023-10-31 18:02:06</td>\n",
       "      <td>4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4</td>\n",
       "      <td>event</td>\n",
       "      <td>negative</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>Annette Henderson</td>\n",
       "      <td>social media</td>\n",
       "      <td>German</td>\n",
       "      <td>confused</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>returning customers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YOonrpgxp9</td>\n",
       "      <td>Bad every reflect huge contain.</td>\n",
       "      <td>Policy argue agree character go recent. When r...</td>\n",
       "      <td>2023-10-31 18:02:06</td>\n",
       "      <td>74c97616-9df6-460d-991d-c6f6f6ae5354</td>\n",
       "      <td>location</td>\n",
       "      <td>neutral</td>\n",
       "      <td>specific outcome</td>\n",
       "      <td>Nicholas Haney</td>\n",
       "      <td>mobile app</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>London</td>\n",
       "      <td>returning customers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID                      User Utterance  \\\n",
       "0  uKqYhMMQ5S  Charge bar between follow student.   \n",
       "1  YOonrpgxp9     Bad every reflect huge contain.   \n",
       "\n",
       "                                        Bot Response            Timestamp  \\\n",
       "0  Important law into large example range. Player...  2023-10-31 18:02:06   \n",
       "1  Policy argue agree character go recent. When r...  2023-10-31 18:02:06   \n",
       "\n",
       "                     Context/Session ID  Entities User Feedback  \\\n",
       "0  4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4     event      negative   \n",
       "1  74c97616-9df6-460d-991d-c6f6f6ae5354  location       neutral   \n",
       "\n",
       "  Conversation Outcome       User Profile Channel/Platform Language  \\\n",
       "0           incomplete  Annette Henderson     social media   German   \n",
       "1     specific outcome     Nicholas Haney       mobile app  Chinese   \n",
       "\n",
       "  User Emotion/Sentiment Location         User Segment  \n",
       "0               confused   Sydney  returning customers  \n",
       "1             frustrated   London  returning customers  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('chatbot_dataset.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77d7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['User Utterance']\n",
    "y=df['Bot Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8bc93c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Important law into large example range. Player seem force with partner sometimes happen southern.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3881720c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Charge bar between follow student.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9354d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[\"My name is Bablu\",\"Bablu goes to college\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d980c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68a8d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=tokenizer.texts_to_sequences(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f3a2580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 1], [1, 5, 6, 7]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5533b7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bablu': 1, 'my': 2, 'name': 3, 'is': 4, 'goes': 5, 'to': 6, 'college': 7}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b4a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 dimensions for each word\n",
    "import math\n",
    "def positionalEncodings(sequence):\n",
    "    \n",
    "    PE=[]\n",
    "    d_model=4\n",
    "    for pos in range(sequence):\n",
    "        EncodingsOfEach=[]\n",
    "        for i in range(d_model):\n",
    "            if i%2==0:\n",
    "                temp=pos/(math.pow(10000,(2*i)/d_model))\n",
    "                EncodingsOfEach.append(math.sin(temp))\n",
    "            else:\n",
    "                temp=pos/(math.pow(10000,(2*(i-1))/d_model))\n",
    "                EncodingsOfEach.append(math.cos(temp))\n",
    "        PE.append(EncodingsOfEach)\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2c26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input will be the embedding(+PE) \n",
    "# eg:[[1,0,1,0],[0,1,0,1],[1,1,1,1]]\n",
    "def selfAttention(embeddings,W_q, W_k,W_v):\n",
    "    numberOfWords=len(embeddings)\n",
    "    Q_K_V_ofAllWords=[]\n",
    "    for i in range(numberOfWords):\n",
    "        Q_of_given_word=np.matmul(embeddings[i],W_q)\n",
    "        K_of_given_word=np.matmul(embeddings[i],W_k)\n",
    "        V_of_given_word=np.matmul(embeddings[i],W_v)\n",
    "        temp=[]\n",
    "        temp.append(Q_of_given_word)\n",
    "        temp.append(K_of_given_word)\n",
    "        temp.append(V_of_given_word)\n",
    "        Q_K_V_ofAllWords.append(temp)\n",
    "    d_k=math.sqrt(len(Q_K_V_ofAllWords[0][1]))\n",
    "    scoreOfAllWords=[]\n",
    "    for i in range(numberOfWords):\n",
    "        query=Q_K_V_ofAllWords[i][0]\n",
    "        scoreOfEachWord=[]\n",
    "        for j in range(numberOfWords):\n",
    "            key=Q_K_V_ofAllWords[j][1]\n",
    "            scoreOfEachWord.append(np.matmul(query,key)/d_k)\n",
    "        scoreOfAllWords.append(scoreOfEachWord)\n",
    "    attentionWeightsOfAllWords=[]\n",
    "    for i in range(numberOfWords):\n",
    "        attentionWeightsOfAllWords.append(softmax(scoreOfAllWords[i]))\n",
    "    \n",
    "    finalAttentionOutput=[]\n",
    "    for i in range(numberOfWords):\n",
    "        d_v = len(Q_K_V_ofAllWords[0][2])\n",
    "        temp = np.zeros(d_v)\n",
    "        for j in range(numberOfWords):\n",
    "            temp += attentionWeightsOfAllWords[i][j] * Q_K_V_ofAllWords[j][2]\n",
    "        finalAttentionOutput.append(temp)\n",
    "    return finalAttentionOutput\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0465a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_and_normalize(output_of_previous,input_of_previous):\n",
    "    #added=output_of_previous+input_of_previous\n",
    "    output=[]\n",
    "    eps = 1e-6\n",
    "    for i in range(len(output_of_previous)):\n",
    "        added=output_of_previous[i]+input_of_previous[i]\n",
    "        mean = np.mean(added)\n",
    "        std_dev = np.std(added)\n",
    "        normalized_array=(added-mean)/(std_dev+eps)\n",
    "        output.append(normalized_array)\n",
    "    return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe70a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeedForwardNN(x,W1,b1,W2,b2):\n",
    "    output=[]\n",
    "    for i in range(len(x)):\n",
    "        hidden=np.maximum(0,np.matmul(x[i],W1)+b1)\n",
    "        out=np.matmul(hidden,W2)+b2\n",
    "        output.append(out)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c464b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(positional_encodings_plus_embeddings,W_q,W_k,W_v,W1,b1,W2,b2):\n",
    "    self_attn_output=selfAttention(positional_encodings_plus_embeddings,W_q,W_k,W_v)\n",
    "    add_and_normalize_1_output=Add_and_normalize(self_attn_output,positional_encodings_plus_embeddings)\n",
    "    ffn_output=FeedForwardNN(add_and_normalize_1_output,W1,b1,W2,b2)\n",
    "    encoder_output=Add_and_normalize(ffn_output,add_and_normalize_1_output)\n",
    "    return encoder_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ff6bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=np.array([[1,0,1,0],[0,1,0,1],[1,1,1,1]])\n",
    "positional_encodings=positionalEncodings(len(embeddings))\n",
    "embeddings_plus_PE=embeddings+positional_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d150a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = embeddings_plus_PE.shape[1]\n",
    "\n",
    "W_q = np.eye(d_model)\n",
    "W_k = np.eye(d_model)\n",
    "W_v = np.eye(d_model)\n",
    "\n",
    "W1 = np.random.randn(d_model, 256)\n",
    "b1 = np.zeros(256)\n",
    "W2 = np.random.randn(256, d_model)\n",
    "b2 = np.zeros(d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ad2ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.34765644,  1.10364403,  0.71181009, -1.46779769]), array([ 0.67625412,  0.40425863,  0.64200858, -1.72252133]), array([-1.31619964,  1.01768178,  0.91977317, -0.62125531])]\n"
     ]
    }
   ],
   "source": [
    "print(Encoder(embeddings_plus_PE,W_q,W_k,W_v,W1,b1,W2,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c44cbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params = []\n",
    "for _ in range(6):\n",
    "    params = {\n",
    "        \"W_q\": np.random.randn(d_model, d_model),\n",
    "        \"W_k\": np.random.randn(d_model, d_model),\n",
    "        \"W_v\": np.random.randn(d_model, d_model),\n",
    "        \"W1\": np.random.randn(d_model, 256),\n",
    "        \"b1\": np.zeros(256),\n",
    "        \"W2\": np.random.randn(256, d_model),\n",
    "        \"b2\": np.zeros(d_model)\n",
    "    }\n",
    "    encoder_params.append(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd844d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoderStack(x, encoder_params):\n",
    "    for layer in encoder_params:\n",
    "        x = Encoder(\n",
    "            x,\n",
    "            layer[\"W_q\"],\n",
    "            layer[\"W_k\"],\n",
    "            layer[\"W_v\"],\n",
    "            layer[\"W1\"],\n",
    "            layer[\"b1\"],\n",
    "            layer[\"W2\"],\n",
    "            layer[\"b2\"]\n",
    "        )\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fed8bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1.58890413,  0.06480686, -1.05467422, -0.59903678]), array([ 1.58869243,  0.06561651, -1.05450978, -0.59979916]), array([ 1.58870041,  0.06564389, -1.05443127, -0.59991303])]\n"
     ]
    }
   ],
   "source": [
    "print(encoderStack(embeddings_plus_PE,encoder_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be702d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnnProject2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
