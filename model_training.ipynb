{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8130f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0518e5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>User Utterance</th>\n",
       "      <th>Bot Response</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Context/Session ID</th>\n",
       "      <th>Entities</th>\n",
       "      <th>User Feedback</th>\n",
       "      <th>Conversation Outcome</th>\n",
       "      <th>User Profile</th>\n",
       "      <th>Channel/Platform</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Emotion/Sentiment</th>\n",
       "      <th>Location</th>\n",
       "      <th>User Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uKqYhMMQ5S</td>\n",
       "      <td>Charge bar between follow student.</td>\n",
       "      <td>Important law into large example range. Player...</td>\n",
       "      <td>2023-10-31 18:02:06</td>\n",
       "      <td>4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4</td>\n",
       "      <td>event</td>\n",
       "      <td>negative</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>Annette Henderson</td>\n",
       "      <td>social media</td>\n",
       "      <td>German</td>\n",
       "      <td>confused</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>returning customers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YOonrpgxp9</td>\n",
       "      <td>Bad every reflect huge contain.</td>\n",
       "      <td>Policy argue agree character go recent. When r...</td>\n",
       "      <td>2023-10-31 18:02:06</td>\n",
       "      <td>74c97616-9df6-460d-991d-c6f6f6ae5354</td>\n",
       "      <td>location</td>\n",
       "      <td>neutral</td>\n",
       "      <td>specific outcome</td>\n",
       "      <td>Nicholas Haney</td>\n",
       "      <td>mobile app</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>London</td>\n",
       "      <td>returning customers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID                      User Utterance  \\\n",
       "0  uKqYhMMQ5S  Charge bar between follow student.   \n",
       "1  YOonrpgxp9     Bad every reflect huge contain.   \n",
       "\n",
       "                                        Bot Response            Timestamp  \\\n",
       "0  Important law into large example range. Player...  2023-10-31 18:02:06   \n",
       "1  Policy argue agree character go recent. When r...  2023-10-31 18:02:06   \n",
       "\n",
       "                     Context/Session ID  Entities User Feedback  \\\n",
       "0  4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4     event      negative   \n",
       "1  74c97616-9df6-460d-991d-c6f6f6ae5354  location       neutral   \n",
       "\n",
       "  Conversation Outcome       User Profile Channel/Platform Language  \\\n",
       "0           incomplete  Annette Henderson     social media   German   \n",
       "1     specific outcome     Nicholas Haney       mobile app  Chinese   \n",
       "\n",
       "  User Emotion/Sentiment Location         User Segment  \n",
       "0               confused   Sydney  returning customers  \n",
       "1             frustrated   London  returning customers  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('chatbot_dataset.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77d7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['User Utterance']\n",
    "y=df['Bot Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8bc93c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Important law into large example range. Player seem force with partner sometimes happen southern.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3881720c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Charge bar between follow student.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9354d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[\"My name is Bablu\",\"Bablu goes to college\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d980c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68a8d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=tokenizer.texts_to_sequences(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f3a2580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 1], [1, 5, 6, 7]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5533b7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bablu': 1, 'my': 2, 'name': 3, 'is': 4, 'goes': 5, 'to': 6, 'college': 7}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45b4a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 dimensions for each word\n",
    "import math\n",
    "def positionalEncodings(sequence):\n",
    "    \n",
    "    PE=[]\n",
    "    d_model=4\n",
    "    for pos in range(sequence):\n",
    "        EncodingsOfEach=[]\n",
    "        for i in range(d_model):\n",
    "            if i%2==0:\n",
    "                temp=pos/(math.pow(10000,(2*i)/d_model))\n",
    "                EncodingsOfEach.append(math.sin(temp))\n",
    "            else:\n",
    "                temp=pos/(math.pow(10000,(2*(i-1))/d_model))\n",
    "                EncodingsOfEach.append(math.cos(temp))\n",
    "        PE.append(EncodingsOfEach)\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54556273",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"The\", \"cat\", \"sat\"]\n",
    "PE=(positionalEncodings(len(tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37742188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,0,1,0]\n",
    "b=np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "result=np.matmul(a,b)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8bbe099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(4, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "a=np.array([1,0,1,0])\n",
    "b=np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "result=np.matmul(a,b)\n",
    "result\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b2c26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input will be the embedding(+PE) \n",
    "# eg:[[1,0,1,0],[0,1,0,1],[1,1,1,1]]\n",
    "def selfAttention(embeddings,W_q, W_k,W_v):\n",
    "    numberOfWords=len(embeddings)\n",
    "    Q_K_V_ofAllWords=[]\n",
    "    for i in range(numberOfWords):\n",
    "        Q_of_given_word=np.matmul(embeddings[i],W_q)\n",
    "        K_of_given_word=np.matmul(embeddings[i],W_k)\n",
    "        V_of_given_word=np.matmul(embeddings[i],W_v)\n",
    "        temp=[]\n",
    "        temp.append(Q_of_given_word)\n",
    "        temp.append(K_of_given_word)\n",
    "        temp.append(V_of_given_word)\n",
    "        Q_K_V_ofAllWords.append(temp)\n",
    "    d_k=math.sqrt(len(Q_K_V_ofAllWords[0][1]))\n",
    "    scoreOfAllWords=[]\n",
    "    for i in range(numberOfWords):\n",
    "        query=Q_K_V_ofAllWords[i][0]\n",
    "        scoreOfEachWord=[]\n",
    "        for j in range(numberOfWords):\n",
    "            key=Q_K_V_ofAllWords[j][1]\n",
    "            scoreOfEachWord.append(np.matmul(query,key)/d_k)\n",
    "        scoreOfAllWords.append(scoreOfEachWord)\n",
    "    attentionWeightsOfAllWords=[]\n",
    "    for i in range(numberOfWords):\n",
    "        attentionWeightsOfAllWords.append(softmax(scoreOfAllWords[i]))\n",
    "    \n",
    "    finalAttentionOutput=[]\n",
    "    for i in range(numberOfWords):\n",
    "        d_v = len(Q_K_V_ofAllWords[0][2])\n",
    "        temp = np.zeros(d_v)\n",
    "        for j in range(numberOfWords):\n",
    "            temp += attentionWeightsOfAllWords[i][j] * Q_K_V_ofAllWords[j][2]\n",
    "        finalAttentionOutput.append(temp)\n",
    "    return finalAttentionOutput\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c557ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_matrix=np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "embeddings=np.array([[1,0,1,0],[0,1,0,1],[1,1,1,1]])\n",
    "x=(selfAttention(embeddings,temp_matrix,temp_matrix,temp_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9057e465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.8446376, 0.5776812, 0.8446376, 0.5776812]),\n",
       " array([0.5776812, 0.8446376, 0.5776812, 0.8446376]),\n",
       " array([0.78805844, 0.78805844, 0.78805844, 0.78805844])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ece65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=x+embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0465a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_and_normalize(output_of_previous,input_of_previous):\n",
    "    added=output_of_previous+input_of_previous\n",
    "    output=[]\n",
    "    eps = 1e-6\n",
    "    for i in range(len(added)):\n",
    "        mean = np.mean(added[i])\n",
    "        std_dev = np.std(added[i])\n",
    "        normalized_array=(added[i]-mean)/(std_dev+eps)\n",
    "        output.append(normalized_array)\n",
    "    return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c78475c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1=(Add_and_normalize(x,embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b6e166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnnProject2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
