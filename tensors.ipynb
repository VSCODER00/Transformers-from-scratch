{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ae3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d10464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def positionalEncodings(sequence):\n",
    "    \n",
    "    PE=[]\n",
    "    d_model=64\n",
    "    for pos in range(sequence):\n",
    "        EncodingsOfEach=[]\n",
    "        for i in range(d_model):\n",
    "            if i%2==0:\n",
    "                temp=pos/(math.pow(10000,(2*i)/d_model))\n",
    "                EncodingsOfEach.append(math.sin(temp))\n",
    "            else:\n",
    "                temp=pos/(math.pow(10000,(2*(i-1))/d_model))\n",
    "                EncodingsOfEach.append(math.cos(temp))\n",
    "        PE.append(EncodingsOfEach)\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48fff696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def selfAttention(embeddings, W_q, W_k, W_v,mask):\n",
    "#     batch_size = tf.shape(embeddings)[0]\n",
    "#     seq_len = tf.shape(embeddings)[1]\n",
    "\n",
    "#     batch_outputs = []\n",
    "\n",
    "#     for b in range(batch_size):\n",
    "#         x = embeddings[b]            # (seq_len, d_model)\n",
    "\n",
    "#         Q, K, V = [], [], []\n",
    "#         for i in range(seq_len):\n",
    "#             x_i = tf.expand_dims(x[i], 0)   # (1, d_model)\n",
    "#             Q.append(tf.matmul(x_i, W_q))\n",
    "#             K.append(tf.matmul(x_i, W_k))\n",
    "#             V.append(tf.matmul(x_i, W_v))\n",
    "\n",
    "#         d_k = tf.math.sqrt(tf.cast(tf.shape(K[0])[1], tf.float32))\n",
    "\n",
    "#         attention_outputs = []\n",
    "\n",
    "#         for i in range(seq_len):\n",
    "#             score_list = []\n",
    "#             for j in range(seq_len):\n",
    "#                 score = tf.matmul(Q[i], K[j], transpose_b=True)[0, 0] / d_k\n",
    "#                 score=score+mask[i][j]\n",
    "#                 score_list.append(score)\n",
    "\n",
    "#             scores = tf.stack(score_list)\n",
    "#             weights = tf.nn.softmax(scores)\n",
    "\n",
    "#             output = tf.zeros_like(V[0])\n",
    "#             for j in range(seq_len):\n",
    "#                 output += tf.expand_dims(weights[j], axis=0) * V[j]\n",
    "\n",
    "#             attention_outputs.append(output[0])\n",
    "\n",
    "#         batch_outputs.append(tf.stack(attention_outputs))  # (seq_len, d_model)\n",
    "\n",
    "#     return tf.stack(batch_outputs)  # (batch_size, seq_len, d_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b2e8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfAttention(x, W_q, W_k, W_v):\n",
    "    \"\"\"\n",
    "    x: (batch_size, seq_len, d_model)\n",
    "    W_q, W_k, W_v: (d_model, d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    # Linear projections\n",
    "    Q = tf.matmul(x, W_q)  # (batch, seq_len, d_model)\n",
    "    K = tf.matmul(x, W_k)\n",
    "    V = tf.matmul(x, W_v)\n",
    "\n",
    "    d_k = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "\n",
    "    # Scaled dot-product attention\n",
    "    scores = tf.matmul(Q, K, transpose_b=True)  # (batch, seq_len, seq_len)\n",
    "    scores = scores / tf.math.sqrt(d_k)\n",
    "\n",
    "    weights = tf.nn.softmax(scores, axis=-1)    # (batch, seq_len, seq_len)\n",
    "\n",
    "    output = tf.matmul(weights, V)               # (batch, seq_len, d_model)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adc88dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "def Add_and_normalize(output_of_previous,input_of_previous):\n",
    "    return layer_norm(output_of_previous + input_of_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea40a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeedForwardNN(x, W1, b1, W2, b2):\n",
    "    hidden = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "    out = tf.matmul(hidden, W2) + b2\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5f8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(positional_encodings_plus_embeddings,W_q,W_k,W_v,W1,b1,W2,b2):\n",
    "    self_attn_output=selfAttention(positional_encodings_plus_embeddings,W_q,W_k,W_v)\n",
    "    add_and_normalize_1_output=Add_and_normalize(self_attn_output,positional_encodings_plus_embeddings)\n",
    "    ffn_output=FeedForwardNN(add_and_normalize_1_output,W1,b1,W2,b2)\n",
    "    encoder_output=Add_and_normalize(ffn_output,add_and_normalize_1_output)\n",
    "    return encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e386143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoderStack(x, encoder_params):\n",
    "    for layer in encoder_params:\n",
    "        x = Encoder(\n",
    "            x,\n",
    "            layer[\"W_q\"],\n",
    "            layer[\"W_k\"],\n",
    "            layer[\"W_v\"],\n",
    "            layer[\"W1\"],\n",
    "            layer[\"b1\"],\n",
    "            layer[\"W2\"],\n",
    "            layer[\"b2\"]\n",
    "        )\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8df09",
   "metadata": {},
   "source": [
    "Decoder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7a7cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def masked_Attention(embeddings, W_q, W_k, W_v,mask):\n",
    "#     batch_size = tf.shape(embeddings)[0]\n",
    "#     seq_len = tf.shape(embeddings)[1]\n",
    "\n",
    "#     batch_outputs = []\n",
    "\n",
    "#     for b in range(batch_size):\n",
    "#         x = embeddings[b]            # (seq_len, d_model)\n",
    "\n",
    "#         Q, K, V = [], [], []\n",
    "#         for i in range(seq_len):\n",
    "#             x_i = tf.expand_dims(x[i], 0)   # (1, d_model)\n",
    "#             Q.append(tf.matmul(x_i, W_q))\n",
    "#             K.append(tf.matmul(x_i, W_k))\n",
    "#             V.append(tf.matmul(x_i, W_v))\n",
    "\n",
    "#         d_k = tf.math.sqrt(tf.cast(tf.shape(K[0])[1], tf.float32))\n",
    "\n",
    "#         attention_outputs = []\n",
    "\n",
    "#         for i in range(seq_len):\n",
    "#             score_list = []\n",
    "#             for j in range(seq_len):\n",
    "#                 score = tf.matmul(Q[i], K[j], transpose_b=True)[0, 0] / d_k\n",
    "#                 score=score+mask[i][j]\n",
    "#                 score_list.append(score)\n",
    "\n",
    "#             scores = tf.stack(score_list)\n",
    "#             weights = tf.nn.softmax(scores)\n",
    "\n",
    "#             output = tf.zeros_like(V[0])\n",
    "#             for j in range(seq_len):\n",
    "#                 output += tf.expand_dims(weights[j], axis=0) * V[j]\n",
    "\n",
    "#             attention_outputs.append(output[0])\n",
    "\n",
    "#         batch_outputs.append(tf.stack(attention_outputs))  # (seq_len, d_model)\n",
    "\n",
    "#     return tf.stack(batch_outputs)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "def masked_Attention(embeddings, W_q, W_k, W_v, mask):\n",
    "    # embeddings: (B, T, D)\n",
    "    # mask: (T, T)\n",
    "\n",
    "    # 1. Linear projections\n",
    "    Q = tf.matmul(embeddings, W_q)  # (B, T, D)\n",
    "    K = tf.matmul(embeddings, W_k)  # (B, T, D)\n",
    "    V = tf.matmul(embeddings, W_v)  # (B, T, D)\n",
    "\n",
    "    # 2. Scaled dot-product attention scores\n",
    "    d_k = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "    scores = tf.matmul(Q, K, transpose_b=True)  # (B, T, T)\n",
    "    scores = scores / tf.math.sqrt(d_k)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    scores += (1.0 - mask) * -1e9 \n",
    "\n",
    "    # 3. Apply mask (broadcasted over batch)\n",
    "     # (B, T, T)\n",
    "\n",
    "    # 4. Softmax over last axis (keys)\n",
    "    weights = tf.nn.softmax(scores, axis=-1)  # (B, T, T)\n",
    "\n",
    "    # 5. Weighted sum of values\n",
    "    output = tf.matmul(weights, V)  # (B, T, D)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69282d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Encoder_decoder_attention(encoder_output,prev_layer_output,W_q,W_k,W_v):\n",
    "#     numberOfWords = tf.shape(encoder_output)[0]\n",
    "\n",
    "#     Q, K, V = [], [], []\n",
    "#     for i in range(numberOfWords):\n",
    "#         q_i = tf.expand_dims(prev_layer_output[i], 0)\n",
    "#         enc_i = tf.expand_dims(encoder_output[i], 0)\n",
    "#         Q.append(tf.matmul(q_i, W_q))\n",
    "#         K.append(tf.matmul(enc_i, W_k))\n",
    "#         V.append(tf.matmul(enc_i, W_v))\n",
    "\n",
    "#     d_k = tf.math.sqrt(tf.cast(tf.shape(K[0])[1], tf.float32))\n",
    "\n",
    "#     attention_outputs = []\n",
    "\n",
    "#     for i in range(numberOfWords):\n",
    "#         score_list = []\n",
    "#         for j in range(numberOfWords):\n",
    "#             score = tf.matmul(Q[i], K[j], transpose_b=True)[0, 0] / d_k\n",
    "#             score_list.append(score)\n",
    "\n",
    "#         scores = tf.stack(score_list)\n",
    "#         weights = tf.nn.softmax(scores)\n",
    "\n",
    "#         output = tf.zeros_like(V[0])\n",
    "#         for j in range(numberOfWords):\n",
    "#             output += tf.expand_dims(weights[j], axis=0) * V[j]\n",
    "\n",
    "#         attention_outputs.append(output[0])\n",
    "\n",
    "#     return tf.stack(attention_outputs)\n",
    "\n",
    "def Encoder_decoder_attention(\n",
    "    encoder_output, prev_layer_output, W_q, W_k, W_v\n",
    "):\n",
    "    # encoder_output: (B, S, D)\n",
    "    # prev_layer_output: (B, T, D)\n",
    "\n",
    "    # 1. Projections\n",
    "    Q = tf.matmul(prev_layer_output, W_q)  # (B, T, D)\n",
    "    K = tf.matmul(encoder_output, W_k)     # (B, S, D)\n",
    "    V = tf.matmul(encoder_output, W_v)     # (B, S, D)\n",
    "\n",
    "    # 2. Scaled dot-product attention\n",
    "    d_k = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "    scores = tf.matmul(Q, K, transpose_b=True)  # (B, T, S)\n",
    "    scores = scores / tf.math.sqrt(d_k)\n",
    "\n",
    "    # 3. Softmax over encoder tokens\n",
    "    weights = tf.nn.softmax(scores, axis=-1)  # (B, T, S)\n",
    "\n",
    "    # 4. Weighted sum\n",
    "    output = tf.matmul(weights, V)  # (B, T, D)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5130bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(positional_encodings_plus_embeddings,encoder_output,W_q_self,W_k_self,W_v_self,W_q_cross,W_k_cross,W_v_cross,mask,W1,b1,W2,b2):\n",
    "    masked_self_attn_output=masked_Attention(positional_encodings_plus_embeddings,W_q_self,W_k_self,W_v_self,mask)\n",
    "    add_and_normalize_1_output=Add_and_normalize(masked_self_attn_output,positional_encodings_plus_embeddings)\n",
    "    encoder_decoder_attn_output=Encoder_decoder_attention(encoder_output,add_and_normalize_1_output,W_q_cross,W_k_cross,W_v_cross)\n",
    "    add_and_normalize_2_output=Add_and_normalize(encoder_decoder_attn_output,add_and_normalize_1_output)\n",
    "    ffn_output=FeedForwardNN(add_and_normalize_2_output,W1,b1,W2,b2)\n",
    "    decoder_output=Add_and_normalize(ffn_output,add_and_normalize_2_output)\n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fa646e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_mask(d):\n",
    "    mask = tf.linalg.band_part(tf.ones((d, d)), -1, 0)\n",
    "    return (1.0 - mask) * -1e9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd4c1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoderStack(x,decoder_params,encoder_output):\n",
    "    seq_len = x.shape[1]       # current sequence length\n",
    "    mask = causal_mask(seq_len)\n",
    "    for layer in decoder_params:\n",
    "        x=decoder(x,encoder_output,layer[\"W_q_self\"],layer[\"W_k_self\"],layer[\"W_v_self\"],layer[\"W_q_cross\"],layer[\"W_k_cross\"],layer[\"W_v_cross\"],mask,layer[\"W1\"],layer[\"b1\"],layer[\"W2\"],layer[\"b2\"])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e5ea5",
   "metadata": {},
   "source": [
    "Preparing the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b07759c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "816d6504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>User Utterance</th>\n",
       "      <th>Bot Response</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Context/Session ID</th>\n",
       "      <th>Entities</th>\n",
       "      <th>User Feedback</th>\n",
       "      <th>Conversation Outcome</th>\n",
       "      <th>User Profile</th>\n",
       "      <th>Channel/Platform</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Emotion/Sentiment</th>\n",
       "      <th>Location</th>\n",
       "      <th>User Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uKqYhMMQ5S</td>\n",
       "      <td>Charge bar between follow student.</td>\n",
       "      <td>Important law into large example range. Player...</td>\n",
       "      <td>2023-10-31 18:02:06</td>\n",
       "      <td>4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4</td>\n",
       "      <td>event</td>\n",
       "      <td>negative</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>Annette Henderson</td>\n",
       "      <td>social media</td>\n",
       "      <td>German</td>\n",
       "      <td>confused</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>returning customers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID                      User Utterance  \\\n",
       "0  uKqYhMMQ5S  Charge bar between follow student.   \n",
       "\n",
       "                                        Bot Response            Timestamp  \\\n",
       "0  Important law into large example range. Player...  2023-10-31 18:02:06   \n",
       "\n",
       "                     Context/Session ID Entities User Feedback  \\\n",
       "0  4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4    event      negative   \n",
       "\n",
       "  Conversation Outcome       User Profile Channel/Platform Language  \\\n",
       "0           incomplete  Annette Henderson     social media   German   \n",
       "\n",
       "  User Emotion/Sentiment Location         User Segment  \n",
       "0               confused   Sydney  returning customers  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('chatbot_dataset.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36fd360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['User Utterance']\n",
    "y=df['Bot Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2fc27da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Charge bar between follow student.\n",
       "1               Bad every reflect huge contain.\n",
       "2       Glass remember many dog director under.\n",
       "3           Help charge record many talk tough.\n",
       "4               Position not man much material.\n",
       "                         ...                   \n",
       "9995           How major might home gun reduce.\n",
       "9996          Result executive some commercial.\n",
       "9997                Require week affect factor.\n",
       "9998                    Film I green like song.\n",
       "9999                   Wonder majority million.\n",
       "Name: User Utterance, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39a405b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(temp):\n",
    "    temp=temp.lower()\n",
    "    temp=temp.replace(\".\",\"\")\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "631211b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.apply(clean_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae82fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            charge bar between follow student\n",
       "1               bad every reflect huge contain\n",
       "2       glass remember many dog director under\n",
       "3           help charge record many talk tough\n",
       "4               position not man much material\n",
       "                         ...                  \n",
       "9995           how major might home gun reduce\n",
       "9996          result executive some commercial\n",
       "9997                require week affect factor\n",
       "9998                    film i green like song\n",
       "9999                   wonder majority million\n",
       "Name: User Utterance, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2bcbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d891ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input=\"<sos> \"+y\n",
    "y_target=y+\" <eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f36bdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b623bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(filters='',oov_token=\"OOV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24f088eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(x)+list(y_input)+list(y_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbfc5de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33baaa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tokenizer.texts_to_sequences(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e6e99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input=tokenizer.texts_to_sequences(y_input)\n",
    "y_target=tokenizer.texts_to_sequences(y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcf3c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "x=pad_sequences(x,padding='post')\n",
    "y_input=pad_sequences(y_input,padding='post')\n",
    "y_target=pad_sequences(y_target,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c57e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfWords=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3410603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=numberOfWords,\n",
    "    output_dim=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cfb8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=embedding_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3543748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input=embedding_layer(y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f929b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PE=positionalEncodings(len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "898e13e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x+PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e770e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "PE1=positionalEncodings(len(y_input[0]))\n",
    "y_input=y_input+PE1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6806228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_model=x[0].shape[1]\n",
    "encoder_params = []\n",
    "for _ in range(6):\n",
    "    params = {\n",
    "        \"W_q\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_k\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_v\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W1\": tf.Variable(tf.random.normal(shape=(d_model,256))),\n",
    "        \"b1\": tf.Variable(tf.random.normal(shape=(256,))),\n",
    "        \"W2\": tf.Variable(tf.random.normal(shape=(256,d_model))),\n",
    "        \"b2\": tf.Variable(tf.random.normal(shape=(d_model,)))\n",
    "    }\n",
    "    encoder_params.append(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0715889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output=(encoderStack(x,encoder_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b5684ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=y_input[0].shape[1]\n",
    "numberOfWordsperSentence=y_input[0].shape[0]\n",
    "mask=causal_mask(numberOfWordsperSentence)\n",
    "decoder_params = []\n",
    "\n",
    "for _ in range(6):\n",
    "    params = {\n",
    "        \"W_q_self\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_k_self\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_v_self\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_q_cross\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_k_cross\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_v_cross\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W1\": tf.Variable(tf.random.normal(shape=(d_model,256))),\n",
    "        \"b1\": tf.Variable(tf.random.normal(shape=(256,))),\n",
    "        \"W2\": tf.Variable(tf.random.normal(shape=(256,d_model))),\n",
    "        \"b2\": tf.Variable(tf.random.normal(shape=(d_model,)))\n",
    "    }\n",
    "    decoder_params.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2183e48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.35350922  0.24897848  0.824047   ... -1.2552556   0.5592487\n",
      "    1.2884918 ]\n",
      "  [ 0.3534373   0.24865519  0.82367396 ... -1.2548338   0.5595525\n",
      "    1.2884636 ]\n",
      "  [ 0.35332078  0.24860422  0.8237599  ... -1.2544377   0.55886894\n",
      "    1.2883502 ]\n",
      "  ...\n",
      "  [ 0.35370895  0.248875    0.8240993  ... -1.2548683   0.55925465\n",
      "    1.2880447 ]\n",
      "  [ 0.3536807   0.24893267  0.8241639  ... -1.2546885   0.5590889\n",
      "    1.2881393 ]\n",
      "  [ 0.35374263  0.24895956  0.8241448  ... -1.2546397   0.5590787\n",
      "    1.2880994 ]]\n",
      "\n",
      " [[ 0.3685977   0.1748299   0.83255726 ... -1.3459191   0.5937771\n",
      "    1.3169351 ]\n",
      "  [ 0.36854485  0.17497113  0.8320781  ... -1.3460659   0.5939615\n",
      "    1.3170239 ]\n",
      "  [ 0.36858293  0.17512603  0.8322284  ... -1.3460875   0.59386307\n",
      "    1.317037  ]\n",
      "  ...\n",
      "  [ 0.36861688  0.1748479   0.83251256 ... -1.3459136   0.59383476\n",
      "    1.3167218 ]\n",
      "  [ 0.3686169   0.17484792  0.83251256 ... -1.3459136   0.59383476\n",
      "    1.3167219 ]\n",
      "  [ 0.36861694  0.17484793  0.83251256 ... -1.3459135   0.59383476\n",
      "    1.3167219 ]]\n",
      "\n",
      " [[ 0.37300092  0.23377377  0.8003674  ... -1.2749211   0.5965338\n",
      "    1.3269116 ]\n",
      "  [ 0.3735177   0.233966    0.799794   ... -1.2750828   0.59660023\n",
      "    1.3267746 ]\n",
      "  [ 0.37327516  0.23392127  0.8001663  ... -1.2744554   0.5964937\n",
      "    1.326613  ]\n",
      "  ...\n",
      "  [ 0.3735359   0.23361686  0.80057615 ... -1.2747424   0.5962495\n",
      "    1.3268088 ]\n",
      "  [ 0.37354288  0.23360805  0.8004701  ... -1.2746313   0.5962702\n",
      "    1.3268098 ]\n",
      "  [ 0.37354085  0.23360895  0.80046356 ... -1.2746274   0.59626746\n",
      "    1.32681   ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.4075869   0.22165506  0.79509485 ... -1.3115113   0.643868\n",
      "    1.2973495 ]\n",
      "  [ 0.407784    0.22183791  0.7953097  ... -1.3113476   0.644026\n",
      "    1.2969586 ]\n",
      "  [ 0.4076104   0.2219656   0.79514414 ... -1.3117924   0.64379007\n",
      "    1.297328  ]\n",
      "  ...\n",
      "  [ 0.40764982  0.22205357  0.7953154  ... -1.3114699   0.64385706\n",
      "    1.2970096 ]\n",
      "  [ 0.40764984  0.22205362  0.79531544 ... -1.31147     0.64385706\n",
      "    1.2970097 ]\n",
      "  [ 0.40764982  0.22205365  0.79531544 ... -1.3114699   0.64385706\n",
      "    1.2970098 ]]\n",
      "\n",
      " [[ 0.34892508  0.22270647  0.8060203  ... -1.3559632   0.6434344\n",
      "    1.3368418 ]\n",
      "  [ 0.34901133  0.22292824  0.8060642  ... -1.3559881   0.64349693\n",
      "    1.3366264 ]\n",
      "  [ 0.34906507  0.2228861   0.8059725  ... -1.3560064   0.6434793\n",
      "    1.3365709 ]\n",
      "  ...\n",
      "  [ 0.34881747  0.22268628  0.8060396  ... -1.3561844   0.64348173\n",
      "    1.3369578 ]\n",
      "  [ 0.34881747  0.22268625  0.8060396  ... -1.3561844   0.64348173\n",
      "    1.3369577 ]\n",
      "  [ 0.34881744  0.22268626  0.80603945 ... -1.3561844   0.6434818\n",
      "    1.3369577 ]]\n",
      "\n",
      " [[ 0.35285753  0.19193813  0.825891   ... -1.3550014   0.60206026\n",
      "    1.323384  ]\n",
      "  [ 0.35262942  0.19215877  0.82583743 ... -1.3550261   0.60207313\n",
      "    1.3236398 ]\n",
      "  [ 0.352274    0.19232325  0.8255854  ... -1.3556002   0.6022428\n",
      "    1.3232442 ]\n",
      "  ...\n",
      "  [ 0.35249776  0.19211754  0.8257384  ... -1.3552339   0.6019709\n",
      "    1.3234    ]\n",
      "  [ 0.35249752  0.19211684  0.82573795 ... -1.3552343   0.6019705\n",
      "    1.3233992 ]\n",
      "  [ 0.35249752  0.19211684  0.82573795 ... -1.3552343   0.6019705\n",
      "    1.3233992 ]]], shape=(10000, 19, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(decoderStack(y_input,decoder_params,encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "106a0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_forward(x_input, y_input,\n",
    "                        encoder_params, decoder_params,\n",
    "                        W_out, b_out):\n",
    "\n",
    "    encoder_output = encoderStack(x_input, encoder_params)\n",
    "    decoder_output = decoderStack(y_input, decoder_params, encoder_output)\n",
    "    logits = tf.einsum(\"btd,dk->btk\", decoder_output, W_out) + b_out\n",
    "\n",
    "    return logits  # (B, T, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cb92853",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = numberOfWords # or whatever your tokenizer size is\n",
    "\n",
    "W_out = tf.Variable(tf.random.normal((64, vocab_size)))\n",
    "b_out = tf.Variable(tf.zeros((vocab_size,)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32ae00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction=\"none\"\n",
    ")\n",
    "\n",
    "def masked_loss(y_true, logits):\n",
    "    # logits: (B, T, V)\n",
    "    # y_true: (B, T)\n",
    "\n",
    "    vocab_size = tf.shape(logits)[-1]\n",
    "\n",
    "    # flatten\n",
    "    logits = tf.reshape(logits, [-1, vocab_size])  # (B*T, V)\n",
    "    y_true = tf.reshape(y_true, [-1])               # (B*T)\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y_true,\n",
    "        logits=logits\n",
    "    )\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "068720d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_vars = []\n",
    "\n",
    "for layer in encoder_params:\n",
    "    trainable_vars.extend(layer.values())\n",
    "\n",
    "for layer in decoder_params:\n",
    "    trainable_vars.extend(layer.values())\n",
    "\n",
    "trainable_vars.extend([W_out, b_out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ff5f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-4,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.98,\n",
    "    epsilon=1e-9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d06deecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x_input, y_input, y_target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = transformer_forward(\n",
    "            x_input, y_input,\n",
    "            encoder_params, decoder_params,\n",
    "            W_out, b_out\n",
    "        )\n",
    "        loss = masked_loss(y_target, logits)\n",
    "\n",
    "    grads = tape.gradient(loss, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(grads, trainable_vars))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44aa84a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 17.5515\n",
      "Epoch 2, Loss: 14.0488\n",
      "Epoch 3, Loss: 12.2820\n",
      "Epoch 4, Loss: 10.8817\n",
      "Epoch 5, Loss: 9.7726\n",
      "Epoch 6, Loss: 8.9350\n",
      "Epoch 7, Loss: 8.3348\n",
      "Epoch 8, Loss: 7.9113\n",
      "Epoch 9, Loss: 7.6021\n",
      "Epoch 10, Loss: 7.3685\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "num_samples = x.shape[0]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for i in range(0, num_samples, BATCH_SIZE):\n",
    "        x_batch = x[i:i+BATCH_SIZE]\n",
    "        y_in_batch = y_input[i:i+BATCH_SIZE]\n",
    "        y_tgt_batch = y_target[i:i+BATCH_SIZE]\n",
    "\n",
    "        # skip last incomplete batch (optional)\n",
    "        if x_batch.shape[0] < BATCH_SIZE:\n",
    "            continue\n",
    "\n",
    "        loss = train_step(x_batch, y_in_batch, y_tgt_batch)\n",
    "        total_loss += loss\n",
    "        steps += 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / steps:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cb86cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 19, 1501)\n"
     ]
    }
   ],
   "source": [
    "logits = transformer_forward(\n",
    "    x[:32],\n",
    "    y_input[:32],\n",
    "    encoder_params,\n",
    "    decoder_params,\n",
    "    W_out,\n",
    "    b_out\n",
    ")\n",
    "\n",
    "print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d410c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 19, 64)\n",
      "(10000, 19)\n"
     ]
    }
   ],
   "source": [
    "print(y_input.shape)   # (B, T)\n",
    "print(y_target.shape)  # (B, T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a38fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10, 64)\n",
      "(10000, 19, 64)\n",
      "(10000, 19)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y_input.shape)   \n",
    "print(y_target.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "504b0f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05736803,  0.5728662 , -0.4638267 , ...,  0.38858372,\n",
       "         0.05703561,  1.0867084 ],\n",
       "       [-0.7731334 , -1.1273875 ,  0.87432116, ...,  1.1872966 ,\n",
       "        -0.16804042,  2.6246243 ],\n",
       "       [ 1.0465385 ,  0.37476498,  0.11576691, ...,  1.3860431 ,\n",
       "        -1.3612062 , -0.942404  ],\n",
       "       ...,\n",
       "       [ 0.2539682 , -1.7078447 ,  0.7882006 , ...,  1.7670351 ,\n",
       "         1.3164395 , -0.97455955],\n",
       "       [-0.6544962 , -0.2958214 , -0.14303397, ..., -1.6947759 ,\n",
       "         0.81154436, -1.305567  ],\n",
       "       [-1.165641  , -0.5689572 , -0.50036865, ..., -0.307711  ,\n",
       "         0.4265408 , -0.6049645 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_params[0][\"W_q\"].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3266b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(\n",
    "    input_sentence,\n",
    "    max_len=30\n",
    "):\n",
    "    \n",
    "    x_ids = tokenizer.texts_to_sequences([input_sentence])\n",
    "    x_ids=pad_sequences(x_ids,padding='post',maxlen=10)\n",
    "    x_ids = tf.constant(x_ids)\n",
    "\n",
    "    x_embed = embedding_layer(x_ids)\n",
    "    x_embed += positionalEncodings(x_embed.shape[0])\n",
    "\n",
    "    encoder_out = encoderStack(x_embed, encoder_params)\n",
    "\n",
    "    # 2. Start decoder with <sos>\n",
    "    sos_id = tokenizer.word_index[\"<sos>\"]\n",
    "    eos_id = tokenizer.word_index[\"<eos>\"]\n",
    "\n",
    "    y_ids = tf.constant([[sos_id]])\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        y_embed = embedding_layer(y_ids)\n",
    "        y_embed += positionalEncodings(y_embed.shape[0])\n",
    "\n",
    "        decoder_out = decoderStack(y_embed, decoder_params, encoder_out)\n",
    "\n",
    "        logits = tf.einsum(\"btd,dk->btk\", decoder_out, W_out) + b_out\n",
    "\n",
    "        next_token = tf.argmax(logits[:, -1, :], axis=-1).numpy()[0]\n",
    "\n",
    "        if next_token == eos_id:\n",
    "            break\n",
    "\n",
    "        y_ids = tf.concat(\n",
    "            [y_ids, [[next_token]]],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    return tokenizer.sequences_to_texts(y_ids.numpy())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba318339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos>\n"
     ]
    }
   ],
   "source": [
    "print(greedy_decode(\"Hello what are you doing and how is life and the moon is the only light\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b5c8d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ids = tokenizer.texts_to_sequences([\"Hello what are you doing now and how is life\"])\n",
    "x_ids=pad_sequences(x_ids,padding='post',maxlen=10)\n",
    "x_ids = tf.constant(x_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ab19a54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[  1, 115,   1,   4,   1,   0,   0,   0,   0,   0]])>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "efe6d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embed = embedding_layer(x_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a2242f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "iric=positionalEncodings(x_embed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9dd77906",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embed=x_embed+iric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d2cbf0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 64), dtype=float32, numpy=\n",
       "array([[[ 2.75616758e-02,  9.66541171e-01,  4.55960520e-02,\n",
       "          9.66299355e-01, -2.42324919e-03,  1.03603590e+00,\n",
       "          1.65901519e-02,  9.63546216e-01, -3.89556773e-02,\n",
       "          1.03848183e+00,  1.14405751e-02,  9.80966210e-01,\n",
       "          4.35198434e-02,  9.51243818e-01,  9.47365910e-03,\n",
       "          9.83551204e-01, -4.39269543e-02,  1.04676902e+00,\n",
       "          3.15343849e-02,  9.55221474e-01, -4.52478416e-02,\n",
       "          1.04918134e+00, -4.25847657e-02,  9.51684892e-01,\n",
       "          2.84588002e-02,  1.02075958e+00, -2.52927430e-02,\n",
       "          1.03773868e+00, -3.01157963e-02,  9.86772180e-01,\n",
       "         -4.07280326e-02,  1.03867781e+00,  4.87259068e-02,\n",
       "          9.55558717e-01, -1.57153383e-02,  1.00135493e+00,\n",
       "          3.52635719e-02,  1.03862929e+00,  3.62424962e-02,\n",
       "          9.68588650e-01, -6.80303574e-03,  9.76093829e-01,\n",
       "         -4.53583859e-02,  9.70077932e-01, -2.27234364e-02,\n",
       "          9.91288662e-01, -4.89297882e-02,  1.01801980e+00,\n",
       "          9.69158486e-03,  9.54384506e-01, -4.95954752e-02,\n",
       "          9.72464919e-01,  1.23650320e-02,  1.00984311e+00,\n",
       "         -5.94687462e-03,  1.01431537e+00, -3.45964544e-02,\n",
       "          9.79064763e-01, -4.95743752e-03,  9.87877548e-01,\n",
       "         -3.35560068e-02,  1.04504108e+00, -2.30555609e-03,\n",
       "          9.56066847e-01],\n",
       "        [-4.58296910e-02,  1.02156270e+00, -4.28903364e-02,\n",
       "          1.04984188e+00, -2.86729932e-02,  9.52298343e-01,\n",
       "         -4.64705378e-03,  9.51036453e-01,  4.44078557e-02,\n",
       "          1.04521215e+00,  3.82719189e-03,  1.01021767e+00,\n",
       "          4.19942252e-02,  1.01341379e+00, -5.72713464e-03,\n",
       "          1.04331696e+00, -2.40410808e-02,  1.01360762e+00,\n",
       "          1.99973471e-02,  9.77723718e-01, -2.69831307e-02,\n",
       "          9.89821672e-01,  1.50403045e-02,  9.87308502e-01,\n",
       "          1.25953816e-02,  1.01391768e+00, -7.74146244e-03,\n",
       "          9.72482085e-01, -4.67889085e-02,  9.83189642e-01,\n",
       "         -4.72182035e-03,  1.04267895e+00, -4.80169430e-02,\n",
       "          9.96432841e-01,  7.05463812e-03,  1.01830208e+00,\n",
       "          7.07639381e-03,  1.00194812e+00, -3.98074873e-02,\n",
       "          1.02430964e+00, -1.26435384e-02,  9.86451864e-01,\n",
       "         -3.18684727e-02,  1.03786266e+00,  4.58101667e-02,\n",
       "          1.01489675e+00, -3.03762034e-03,  9.91773546e-01,\n",
       "          6.14952296e-04,  9.55301881e-01,  3.54015268e-02,\n",
       "          9.74517584e-01,  5.86758927e-03,  9.69172716e-01,\n",
       "         -3.87118831e-02,  9.67543542e-01,  4.54584025e-02,\n",
       "          1.04913449e+00, -2.24519968e-02,  9.81631756e-01,\n",
       "          3.20737995e-02,  9.81488049e-01,  7.74518400e-03,\n",
       "          1.04620337e+00],\n",
       "        [ 2.75616758e-02,  9.66541171e-01,  4.55960520e-02,\n",
       "          9.66299355e-01, -2.42324919e-03,  1.03603590e+00,\n",
       "          1.65901519e-02,  9.63546216e-01, -3.89556773e-02,\n",
       "          1.03848183e+00,  1.14405751e-02,  9.80966210e-01,\n",
       "          4.35198434e-02,  9.51243818e-01,  9.47365910e-03,\n",
       "          9.83551204e-01, -4.39269543e-02,  1.04676902e+00,\n",
       "          3.15343849e-02,  9.55221474e-01, -4.52478416e-02,\n",
       "          1.04918134e+00, -4.25847657e-02,  9.51684892e-01,\n",
       "          2.84588002e-02,  1.02075958e+00, -2.52927430e-02,\n",
       "          1.03773868e+00, -3.01157963e-02,  9.86772180e-01,\n",
       "         -4.07280326e-02,  1.03867781e+00,  4.87259068e-02,\n",
       "          9.55558717e-01, -1.57153383e-02,  1.00135493e+00,\n",
       "          3.52635719e-02,  1.03862929e+00,  3.62424962e-02,\n",
       "          9.68588650e-01, -6.80303574e-03,  9.76093829e-01,\n",
       "         -4.53583859e-02,  9.70077932e-01, -2.27234364e-02,\n",
       "          9.91288662e-01, -4.89297882e-02,  1.01801980e+00,\n",
       "          9.69158486e-03,  9.54384506e-01, -4.95954752e-02,\n",
       "          9.72464919e-01,  1.23650320e-02,  1.00984311e+00,\n",
       "         -5.94687462e-03,  1.01431537e+00, -3.45964544e-02,\n",
       "          9.79064763e-01, -4.95743752e-03,  9.87877548e-01,\n",
       "         -3.35560068e-02,  1.04504108e+00, -2.30555609e-03,\n",
       "          9.56066847e-01],\n",
       "        [ 1.68052427e-02,  9.72626030e-01, -4.57817912e-02,\n",
       "          1.04593754e+00, -5.01043722e-03,  1.02414143e+00,\n",
       "          3.54058482e-02,  1.02721739e+00, -2.24612597e-02,\n",
       "          9.60037291e-01,  1.24515519e-02,  9.79082167e-01,\n",
       "          4.26947810e-02,  9.60454047e-01, -1.15470290e-02,\n",
       "          1.00287282e+00, -2.89647337e-02,  1.04733026e+00,\n",
       "          3.94307710e-02,  1.01886833e+00, -6.99373335e-03,\n",
       "          1.00726044e+00,  2.51803510e-02,  1.04969144e+00,\n",
       "         -4.03326750e-02,  1.03398430e+00,  3.94608639e-02,\n",
       "          1.00626338e+00,  3.76410745e-02,  9.91407990e-01,\n",
       "          3.51943411e-02,  9.93998408e-01, -3.02742608e-02,\n",
       "          1.00004196e+00,  1.59821026e-02,  1.00500572e+00,\n",
       "         -1.80151239e-02,  1.03335989e+00, -4.11379561e-02,\n",
       "          9.63904381e-01,  4.32105772e-02,  1.01280820e+00,\n",
       "         -1.98281053e-02,  9.57371593e-01, -3.39586623e-02,\n",
       "          9.58214641e-01, -4.09241803e-02,  1.03038001e+00,\n",
       "          2.13392042e-02,  1.01762187e+00, -2.20073462e-02,\n",
       "          1.04890001e+00,  2.43569650e-02,  1.00893307e+00,\n",
       "          2.61202790e-02,  9.63718355e-01, -2.01259982e-02,\n",
       "          1.00115216e+00,  9.80750471e-03,  9.58810866e-01,\n",
       "          7.63039663e-03,  1.00471914e+00, -3.87205482e-02,\n",
       "          1.01813030e+00],\n",
       "        [ 2.75616758e-02,  9.66541171e-01,  4.55960520e-02,\n",
       "          9.66299355e-01, -2.42324919e-03,  1.03603590e+00,\n",
       "          1.65901519e-02,  9.63546216e-01, -3.89556773e-02,\n",
       "          1.03848183e+00,  1.14405751e-02,  9.80966210e-01,\n",
       "          4.35198434e-02,  9.51243818e-01,  9.47365910e-03,\n",
       "          9.83551204e-01, -4.39269543e-02,  1.04676902e+00,\n",
       "          3.15343849e-02,  9.55221474e-01, -4.52478416e-02,\n",
       "          1.04918134e+00, -4.25847657e-02,  9.51684892e-01,\n",
       "          2.84588002e-02,  1.02075958e+00, -2.52927430e-02,\n",
       "          1.03773868e+00, -3.01157963e-02,  9.86772180e-01,\n",
       "         -4.07280326e-02,  1.03867781e+00,  4.87259068e-02,\n",
       "          9.55558717e-01, -1.57153383e-02,  1.00135493e+00,\n",
       "          3.52635719e-02,  1.03862929e+00,  3.62424962e-02,\n",
       "          9.68588650e-01, -6.80303574e-03,  9.76093829e-01,\n",
       "         -4.53583859e-02,  9.70077932e-01, -2.27234364e-02,\n",
       "          9.91288662e-01, -4.89297882e-02,  1.01801980e+00,\n",
       "          9.69158486e-03,  9.54384506e-01, -4.95954752e-02,\n",
       "          9.72464919e-01,  1.23650320e-02,  1.00984311e+00,\n",
       "         -5.94687462e-03,  1.01431537e+00, -3.45964544e-02,\n",
       "          9.79064763e-01, -4.95743752e-03,  9.87877548e-01,\n",
       "         -3.35560068e-02,  1.04504108e+00, -2.30555609e-03,\n",
       "          9.56066847e-01],\n",
       "        [-1.07853524e-02,  9.57291245e-01,  3.82538103e-02,\n",
       "          9.98527884e-01, -3.79654169e-02,  1.02601111e+00,\n",
       "         -2.06921250e-03,  9.54080522e-01, -4.70041409e-02,\n",
       "          1.03655601e+00,  2.58566476e-02,  9.57363069e-01,\n",
       "         -3.41568813e-02,  1.00649333e+00, -4.75221276e-02,\n",
       "          1.02870810e+00, -3.14130560e-02,  1.03413844e+00,\n",
       "          9.92570072e-03,  1.03528893e+00,  2.92505510e-02,\n",
       "          1.02982426e+00, -2.76839025e-02,  9.79855597e-01,\n",
       "         -3.87668237e-02,  9.88640249e-01,  3.13746594e-02,\n",
       "          9.76641774e-01, -4.16914821e-02,  9.95620668e-01,\n",
       "         -1.91385746e-02,  1.03815734e+00,  1.37356184e-02,\n",
       "          9.86833930e-01,  1.04924291e-03,  9.98765111e-01,\n",
       "          4.24613245e-02,  1.02571416e+00, -4.23405059e-02,\n",
       "          9.62771893e-01, -1.96566433e-03,  9.61513758e-01,\n",
       "         -2.53894329e-02,  1.01521957e+00,  3.29618715e-02,\n",
       "          1.02727437e+00,  2.51253285e-02,  1.02931345e+00,\n",
       "         -2.93987282e-02,  1.02056396e+00, -4.61434610e-02,\n",
       "          1.01906037e+00, -4.84986417e-02,  1.02082253e+00,\n",
       "         -4.43377383e-02,  9.83741879e-01, -2.14924216e-02,\n",
       "          1.00149560e+00, -3.34906206e-02,  9.66652691e-01,\n",
       "         -2.55345181e-03,  1.03498030e+00, -2.72713900e-02,\n",
       "          1.03160203e+00],\n",
       "        [-1.07853524e-02,  9.57291245e-01,  3.82538103e-02,\n",
       "          9.98527884e-01, -3.79654169e-02,  1.02601111e+00,\n",
       "         -2.06921250e-03,  9.54080522e-01, -4.70041409e-02,\n",
       "          1.03655601e+00,  2.58566476e-02,  9.57363069e-01,\n",
       "         -3.41568813e-02,  1.00649333e+00, -4.75221276e-02,\n",
       "          1.02870810e+00, -3.14130560e-02,  1.03413844e+00,\n",
       "          9.92570072e-03,  1.03528893e+00,  2.92505510e-02,\n",
       "          1.02982426e+00, -2.76839025e-02,  9.79855597e-01,\n",
       "         -3.87668237e-02,  9.88640249e-01,  3.13746594e-02,\n",
       "          9.76641774e-01, -4.16914821e-02,  9.95620668e-01,\n",
       "         -1.91385746e-02,  1.03815734e+00,  1.37356184e-02,\n",
       "          9.86833930e-01,  1.04924291e-03,  9.98765111e-01,\n",
       "          4.24613245e-02,  1.02571416e+00, -4.23405059e-02,\n",
       "          9.62771893e-01, -1.96566433e-03,  9.61513758e-01,\n",
       "         -2.53894329e-02,  1.01521957e+00,  3.29618715e-02,\n",
       "          1.02727437e+00,  2.51253285e-02,  1.02931345e+00,\n",
       "         -2.93987282e-02,  1.02056396e+00, -4.61434610e-02,\n",
       "          1.01906037e+00, -4.84986417e-02,  1.02082253e+00,\n",
       "         -4.43377383e-02,  9.83741879e-01, -2.14924216e-02,\n",
       "          1.00149560e+00, -3.34906206e-02,  9.66652691e-01,\n",
       "         -2.55345181e-03,  1.03498030e+00, -2.72713900e-02,\n",
       "          1.03160203e+00],\n",
       "        [-1.07853524e-02,  9.57291245e-01,  3.82538103e-02,\n",
       "          9.98527884e-01, -3.79654169e-02,  1.02601111e+00,\n",
       "         -2.06921250e-03,  9.54080522e-01, -4.70041409e-02,\n",
       "          1.03655601e+00,  2.58566476e-02,  9.57363069e-01,\n",
       "         -3.41568813e-02,  1.00649333e+00, -4.75221276e-02,\n",
       "          1.02870810e+00, -3.14130560e-02,  1.03413844e+00,\n",
       "          9.92570072e-03,  1.03528893e+00,  2.92505510e-02,\n",
       "          1.02982426e+00, -2.76839025e-02,  9.79855597e-01,\n",
       "         -3.87668237e-02,  9.88640249e-01,  3.13746594e-02,\n",
       "          9.76641774e-01, -4.16914821e-02,  9.95620668e-01,\n",
       "         -1.91385746e-02,  1.03815734e+00,  1.37356184e-02,\n",
       "          9.86833930e-01,  1.04924291e-03,  9.98765111e-01,\n",
       "          4.24613245e-02,  1.02571416e+00, -4.23405059e-02,\n",
       "          9.62771893e-01, -1.96566433e-03,  9.61513758e-01,\n",
       "         -2.53894329e-02,  1.01521957e+00,  3.29618715e-02,\n",
       "          1.02727437e+00,  2.51253285e-02,  1.02931345e+00,\n",
       "         -2.93987282e-02,  1.02056396e+00, -4.61434610e-02,\n",
       "          1.01906037e+00, -4.84986417e-02,  1.02082253e+00,\n",
       "         -4.43377383e-02,  9.83741879e-01, -2.14924216e-02,\n",
       "          1.00149560e+00, -3.34906206e-02,  9.66652691e-01,\n",
       "         -2.55345181e-03,  1.03498030e+00, -2.72713900e-02,\n",
       "          1.03160203e+00],\n",
       "        [-1.07853524e-02,  9.57291245e-01,  3.82538103e-02,\n",
       "          9.98527884e-01, -3.79654169e-02,  1.02601111e+00,\n",
       "         -2.06921250e-03,  9.54080522e-01, -4.70041409e-02,\n",
       "          1.03655601e+00,  2.58566476e-02,  9.57363069e-01,\n",
       "         -3.41568813e-02,  1.00649333e+00, -4.75221276e-02,\n",
       "          1.02870810e+00, -3.14130560e-02,  1.03413844e+00,\n",
       "          9.92570072e-03,  1.03528893e+00,  2.92505510e-02,\n",
       "          1.02982426e+00, -2.76839025e-02,  9.79855597e-01,\n",
       "         -3.87668237e-02,  9.88640249e-01,  3.13746594e-02,\n",
       "          9.76641774e-01, -4.16914821e-02,  9.95620668e-01,\n",
       "         -1.91385746e-02,  1.03815734e+00,  1.37356184e-02,\n",
       "          9.86833930e-01,  1.04924291e-03,  9.98765111e-01,\n",
       "          4.24613245e-02,  1.02571416e+00, -4.23405059e-02,\n",
       "          9.62771893e-01, -1.96566433e-03,  9.61513758e-01,\n",
       "         -2.53894329e-02,  1.01521957e+00,  3.29618715e-02,\n",
       "          1.02727437e+00,  2.51253285e-02,  1.02931345e+00,\n",
       "         -2.93987282e-02,  1.02056396e+00, -4.61434610e-02,\n",
       "          1.01906037e+00, -4.84986417e-02,  1.02082253e+00,\n",
       "         -4.43377383e-02,  9.83741879e-01, -2.14924216e-02,\n",
       "          1.00149560e+00, -3.34906206e-02,  9.66652691e-01,\n",
       "         -2.55345181e-03,  1.03498030e+00, -2.72713900e-02,\n",
       "          1.03160203e+00],\n",
       "        [-1.07853524e-02,  9.57291245e-01,  3.82538103e-02,\n",
       "          9.98527884e-01, -3.79654169e-02,  1.02601111e+00,\n",
       "         -2.06921250e-03,  9.54080522e-01, -4.70041409e-02,\n",
       "          1.03655601e+00,  2.58566476e-02,  9.57363069e-01,\n",
       "         -3.41568813e-02,  1.00649333e+00, -4.75221276e-02,\n",
       "          1.02870810e+00, -3.14130560e-02,  1.03413844e+00,\n",
       "          9.92570072e-03,  1.03528893e+00,  2.92505510e-02,\n",
       "          1.02982426e+00, -2.76839025e-02,  9.79855597e-01,\n",
       "         -3.87668237e-02,  9.88640249e-01,  3.13746594e-02,\n",
       "          9.76641774e-01, -4.16914821e-02,  9.95620668e-01,\n",
       "         -1.91385746e-02,  1.03815734e+00,  1.37356184e-02,\n",
       "          9.86833930e-01,  1.04924291e-03,  9.98765111e-01,\n",
       "          4.24613245e-02,  1.02571416e+00, -4.23405059e-02,\n",
       "          9.62771893e-01, -1.96566433e-03,  9.61513758e-01,\n",
       "         -2.53894329e-02,  1.01521957e+00,  3.29618715e-02,\n",
       "          1.02727437e+00,  2.51253285e-02,  1.02931345e+00,\n",
       "         -2.93987282e-02,  1.02056396e+00, -4.61434610e-02,\n",
       "          1.01906037e+00, -4.84986417e-02,  1.02082253e+00,\n",
       "         -4.43377383e-02,  9.83741879e-01, -2.14924216e-02,\n",
       "          1.00149560e+00, -3.34906206e-02,  9.66652691e-01,\n",
       "         -2.55345181e-03,  1.03498030e+00, -2.72713900e-02,\n",
       "          1.03160203e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "243e1f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 64), dtype=float32, numpy=\n",
       "array([[[-3.8402182e-01,  3.8071486e-01, -1.4521152e+00, -8.0156282e-02,\n",
       "         -2.5665715e-01,  8.9871258e-01,  1.4151897e+00, -2.9854476e-03,\n",
       "          1.7579795e+00, -9.0312648e-01,  4.4051975e-01, -1.3489048e+00,\n",
       "          1.1900598e+00,  1.4108388e-01,  4.6423602e-01, -1.1340650e+00,\n",
       "         -8.4874266e-01, -1.9558892e+00, -1.2075388e+00, -7.4558467e-01,\n",
       "          3.2968691e-01,  1.3915409e+00,  2.5755930e-01,  9.5502484e-01,\n",
       "          7.6846975e-01, -1.1092676e-01,  1.4209023e-01, -3.3388066e-01,\n",
       "         -3.3443296e-01, -5.5233955e-01,  7.5723544e-02,  1.6536520e+00,\n",
       "         -4.3941504e-01,  5.7350218e-01, -1.2600713e+00, -3.7725902e-01,\n",
       "          3.0341351e-01, -1.4200146e+00,  5.6888777e-01,  2.2883797e+00,\n",
       "          1.4143739e+00, -6.8856668e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314559e+00, -1.9169524e-03,\n",
       "         -2.9897302e-01,  1.8312907e-01, -1.7014435e-01, -8.4164613e-01,\n",
       "         -1.4293441e-01,  3.6172581e-01, -1.5780774e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210264e-01,\n",
       "         -3.5734934e-01,  3.4480470e-01,  2.3888350e+00, -1.0822827e+00],\n",
       "        [-3.8402182e-01,  3.8071486e-01, -1.4521152e+00, -8.0156267e-02,\n",
       "         -2.5665715e-01,  8.9871258e-01,  1.4151897e+00, -2.9854104e-03,\n",
       "          1.7579795e+00, -9.0312636e-01,  4.4051969e-01, -1.3489048e+00,\n",
       "          1.1900597e+00,  1.4108385e-01,  4.6423599e-01, -1.1340650e+00,\n",
       "         -8.4874266e-01, -1.9558892e+00, -1.2075388e+00, -7.4558467e-01,\n",
       "          3.2968694e-01,  1.3915409e+00,  2.5755930e-01,  9.5502484e-01,\n",
       "          7.6846975e-01, -1.1092676e-01,  1.4209025e-01, -3.3388066e-01,\n",
       "         -3.3443290e-01, -5.5233955e-01,  7.5723559e-02,  1.6536520e+00,\n",
       "         -4.3941504e-01,  5.7350218e-01, -1.2600713e+00, -3.7725905e-01,\n",
       "          3.0341348e-01, -1.4200146e+00,  5.6888777e-01,  2.2883797e+00,\n",
       "          1.4143739e+00, -6.8856668e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314559e+00, -1.9169748e-03,\n",
       "         -2.9897302e-01,  1.8312907e-01, -1.7014435e-01, -8.4164625e-01,\n",
       "         -1.4293446e-01,  3.6172584e-01, -1.5780771e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210267e-01,\n",
       "         -3.5734934e-01,  3.4480467e-01,  2.3888350e+00, -1.0822827e+00],\n",
       "        [-3.8402182e-01,  3.8071486e-01, -1.4521152e+00, -8.0156282e-02,\n",
       "         -2.5665715e-01,  8.9871258e-01,  1.4151897e+00, -2.9854476e-03,\n",
       "          1.7579795e+00, -9.0312648e-01,  4.4051975e-01, -1.3489048e+00,\n",
       "          1.1900598e+00,  1.4108388e-01,  4.6423602e-01, -1.1340650e+00,\n",
       "         -8.4874266e-01, -1.9558892e+00, -1.2075388e+00, -7.4558467e-01,\n",
       "          3.2968691e-01,  1.3915409e+00,  2.5755930e-01,  9.5502484e-01,\n",
       "          7.6846975e-01, -1.1092676e-01,  1.4209023e-01, -3.3388066e-01,\n",
       "         -3.3443296e-01, -5.5233955e-01,  7.5723544e-02,  1.6536520e+00,\n",
       "         -4.3941504e-01,  5.7350218e-01, -1.2600713e+00, -3.7725902e-01,\n",
       "          3.0341351e-01, -1.4200146e+00,  5.6888777e-01,  2.2883797e+00,\n",
       "          1.4143739e+00, -6.8856668e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314559e+00, -1.9169524e-03,\n",
       "         -2.9897302e-01,  1.8312907e-01, -1.7014435e-01, -8.4164613e-01,\n",
       "         -1.4293441e-01,  3.6172581e-01, -1.5780774e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210264e-01,\n",
       "         -3.5734934e-01,  3.4480470e-01,  2.3888350e+00, -1.0822827e+00],\n",
       "        [-3.8402182e-01,  3.8071477e-01, -1.4521152e+00, -8.0156207e-02,\n",
       "         -2.5665718e-01,  8.9871258e-01,  1.4151897e+00, -2.9854327e-03,\n",
       "          1.7579795e+00, -9.0312648e-01,  4.4051975e-01, -1.3489048e+00,\n",
       "          1.1900598e+00,  1.4108379e-01,  4.6423602e-01, -1.1340650e+00,\n",
       "         -8.4874260e-01, -1.9558892e+00, -1.2075390e+00, -7.4558467e-01,\n",
       "          3.2968694e-01,  1.3915409e+00,  2.5755933e-01,  9.5502472e-01,\n",
       "          7.6846957e-01, -1.1092675e-01,  1.4209023e-01, -3.3388066e-01,\n",
       "         -3.3443284e-01, -5.5233955e-01,  7.5723499e-02,  1.6536520e+00,\n",
       "         -4.3941510e-01,  5.7350212e-01, -1.2600713e+00, -3.7725902e-01,\n",
       "          3.0341354e-01, -1.4200146e+00,  5.6888777e-01,  2.2883794e+00,\n",
       "          1.4143740e+00, -6.8856680e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314560e+00, -1.9169003e-03,\n",
       "         -2.9897302e-01,  1.8312916e-01, -1.7014436e-01, -8.4164625e-01,\n",
       "         -1.4293438e-01,  3.6172581e-01, -1.5780766e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210267e-01,\n",
       "         -3.5734922e-01,  3.4480476e-01,  2.3888350e+00, -1.0822827e+00],\n",
       "        [-3.8402182e-01,  3.8071486e-01, -1.4521152e+00, -8.0156282e-02,\n",
       "         -2.5665715e-01,  8.9871258e-01,  1.4151897e+00, -2.9854476e-03,\n",
       "          1.7579795e+00, -9.0312648e-01,  4.4051975e-01, -1.3489048e+00,\n",
       "          1.1900598e+00,  1.4108388e-01,  4.6423602e-01, -1.1340650e+00,\n",
       "         -8.4874266e-01, -1.9558892e+00, -1.2075388e+00, -7.4558467e-01,\n",
       "          3.2968691e-01,  1.3915409e+00,  2.5755930e-01,  9.5502484e-01,\n",
       "          7.6846975e-01, -1.1092676e-01,  1.4209023e-01, -3.3388066e-01,\n",
       "         -3.3443296e-01, -5.5233955e-01,  7.5723544e-02,  1.6536520e+00,\n",
       "         -4.3941504e-01,  5.7350218e-01, -1.2600713e+00, -3.7725902e-01,\n",
       "          3.0341351e-01, -1.4200146e+00,  5.6888777e-01,  2.2883797e+00,\n",
       "          1.4143739e+00, -6.8856668e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314559e+00, -1.9169524e-03,\n",
       "         -2.9897302e-01,  1.8312907e-01, -1.7014435e-01, -8.4164613e-01,\n",
       "         -1.4293441e-01,  3.6172581e-01, -1.5780774e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210264e-01,\n",
       "         -3.5734934e-01,  3.4480470e-01,  2.3888350e+00, -1.0822827e+00],\n",
       "        [-3.8402182e-01,  3.8071486e-01, -1.4521152e+00, -8.0156267e-02,\n",
       "         -2.5665715e-01,  8.9871258e-01,  1.4151897e+00, -2.9854327e-03,\n",
       "          1.7579795e+00, -9.0312636e-01,  4.4051969e-01, -1.3489048e+00,\n",
       "          1.1900597e+00,  1.4108387e-01,  4.6423599e-01, -1.1340650e+00,\n",
       "         -8.4874266e-01, -1.9558892e+00, -1.2075388e+00, -7.4558467e-01,\n",
       "          3.2968694e-01,  1.3915409e+00,  2.5755930e-01,  9.5502472e-01,\n",
       "          7.6846975e-01, -1.1092676e-01,  1.4209023e-01, -3.3388066e-01,\n",
       "         -3.3443296e-01, -5.5233955e-01,  7.5723559e-02,  1.6536520e+00,\n",
       "         -4.3941504e-01,  5.7350218e-01, -1.2600713e+00, -3.7725905e-01,\n",
       "          3.0341348e-01, -1.4200146e+00,  5.6888777e-01,  2.2883797e+00,\n",
       "          1.4143739e+00, -6.8856668e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314559e+00, -1.9169524e-03,\n",
       "         -2.9897302e-01,  1.8312907e-01, -1.7014435e-01, -8.4164625e-01,\n",
       "         -1.4293444e-01,  3.6172584e-01, -1.5780774e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210264e-01,\n",
       "         -3.5734934e-01,  3.4480467e-01,  2.3888350e+00, -1.0822827e+00],\n",
       "        [-3.8402182e-01,  3.8071486e-01, -1.4521152e+00, -8.0156267e-02,\n",
       "         -2.5665715e-01,  8.9871258e-01,  1.4151897e+00, -2.9854327e-03,\n",
       "          1.7579795e+00, -9.0312636e-01,  4.4051969e-01, -1.3489048e+00,\n",
       "          1.1900597e+00,  1.4108387e-01,  4.6423599e-01, -1.1340650e+00,\n",
       "         -8.4874266e-01, -1.9558892e+00, -1.2075388e+00, -7.4558467e-01,\n",
       "          3.2968694e-01,  1.3915409e+00,  2.5755930e-01,  9.5502472e-01,\n",
       "          7.6846975e-01, -1.1092676e-01,  1.4209023e-01, -3.3388066e-01,\n",
       "         -3.3443296e-01, -5.5233955e-01,  7.5723559e-02,  1.6536520e+00,\n",
       "         -4.3941504e-01,  5.7350218e-01, -1.2600713e+00, -3.7725905e-01,\n",
       "          3.0341348e-01, -1.4200146e+00,  5.6888777e-01,  2.2883797e+00,\n",
       "          1.4143739e+00, -6.8856668e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314559e+00, -1.9169524e-03,\n",
       "         -2.9897302e-01,  1.8312907e-01, -1.7014435e-01, -8.4164625e-01,\n",
       "         -1.4293444e-01,  3.6172584e-01, -1.5780774e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210264e-01,\n",
       "         -3.5734934e-01,  3.4480467e-01,  2.3888350e+00, -1.0822827e+00],\n",
       "        [-3.8402182e-01,  3.8071486e-01, -1.4521152e+00, -8.0156267e-02,\n",
       "         -2.5665715e-01,  8.9871258e-01,  1.4151897e+00, -2.9854327e-03,\n",
       "          1.7579795e+00, -9.0312636e-01,  4.4051969e-01, -1.3489048e+00,\n",
       "          1.1900597e+00,  1.4108387e-01,  4.6423599e-01, -1.1340650e+00,\n",
       "         -8.4874266e-01, -1.9558892e+00, -1.2075388e+00, -7.4558467e-01,\n",
       "          3.2968694e-01,  1.3915409e+00,  2.5755930e-01,  9.5502472e-01,\n",
       "          7.6846975e-01, -1.1092676e-01,  1.4209023e-01, -3.3388066e-01,\n",
       "         -3.3443296e-01, -5.5233955e-01,  7.5723559e-02,  1.6536520e+00,\n",
       "         -4.3941504e-01,  5.7350218e-01, -1.2600713e+00, -3.7725905e-01,\n",
       "          3.0341348e-01, -1.4200146e+00,  5.6888777e-01,  2.2883797e+00,\n",
       "          1.4143739e+00, -6.8856668e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314559e+00, -1.9169524e-03,\n",
       "         -2.9897302e-01,  1.8312907e-01, -1.7014435e-01, -8.4164625e-01,\n",
       "         -1.4293444e-01,  3.6172584e-01, -1.5780774e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210264e-01,\n",
       "         -3.5734934e-01,  3.4480467e-01,  2.3888350e+00, -1.0822827e+00],\n",
       "        [-3.8402182e-01,  3.8071486e-01, -1.4521152e+00, -8.0156267e-02,\n",
       "         -2.5665715e-01,  8.9871258e-01,  1.4151897e+00, -2.9854327e-03,\n",
       "          1.7579795e+00, -9.0312636e-01,  4.4051969e-01, -1.3489048e+00,\n",
       "          1.1900597e+00,  1.4108387e-01,  4.6423599e-01, -1.1340650e+00,\n",
       "         -8.4874266e-01, -1.9558892e+00, -1.2075388e+00, -7.4558467e-01,\n",
       "          3.2968694e-01,  1.3915409e+00,  2.5755930e-01,  9.5502472e-01,\n",
       "          7.6846975e-01, -1.1092676e-01,  1.4209023e-01, -3.3388066e-01,\n",
       "         -3.3443296e-01, -5.5233955e-01,  7.5723559e-02,  1.6536520e+00,\n",
       "         -4.3941504e-01,  5.7350218e-01, -1.2600713e+00, -3.7725905e-01,\n",
       "          3.0341348e-01, -1.4200146e+00,  5.6888777e-01,  2.2883797e+00,\n",
       "          1.4143739e+00, -6.8856668e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314559e+00, -1.9169524e-03,\n",
       "         -2.9897302e-01,  1.8312907e-01, -1.7014435e-01, -8.4164625e-01,\n",
       "         -1.4293444e-01,  3.6172584e-01, -1.5780774e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210264e-01,\n",
       "         -3.5734934e-01,  3.4480467e-01,  2.3888350e+00, -1.0822827e+00],\n",
       "        [-3.8402182e-01,  3.8071486e-01, -1.4521152e+00, -8.0156267e-02,\n",
       "         -2.5665715e-01,  8.9871258e-01,  1.4151897e+00, -2.9854327e-03,\n",
       "          1.7579795e+00, -9.0312636e-01,  4.4051969e-01, -1.3489048e+00,\n",
       "          1.1900597e+00,  1.4108387e-01,  4.6423599e-01, -1.1340650e+00,\n",
       "         -8.4874266e-01, -1.9558892e+00, -1.2075388e+00, -7.4558467e-01,\n",
       "          3.2968694e-01,  1.3915409e+00,  2.5755930e-01,  9.5502472e-01,\n",
       "          7.6846975e-01, -1.1092676e-01,  1.4209023e-01, -3.3388066e-01,\n",
       "         -3.3443296e-01, -5.5233955e-01,  7.5723559e-02,  1.6536520e+00,\n",
       "         -4.3941504e-01,  5.7350218e-01, -1.2600713e+00, -3.7725905e-01,\n",
       "          3.0341348e-01, -1.4200146e+00,  5.6888777e-01,  2.2883797e+00,\n",
       "          1.4143739e+00, -6.8856668e-01,  7.3873222e-01, -5.3413892e-01,\n",
       "          1.8211945e+00, -2.2991548e+00, -1.0314559e+00, -1.9169524e-03,\n",
       "         -2.9897302e-01,  1.8312907e-01, -1.7014435e-01, -8.4164625e-01,\n",
       "         -1.4293444e-01,  3.6172584e-01, -1.5780774e-01, -1.2548473e+00,\n",
       "          5.5396032e-01, -1.3351617e+00,  1.2592224e+00,  2.8210264e-01,\n",
       "         -3.5734934e-01,  3.4480467e-01,  2.3888350e+00, -1.0822827e+00]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderStack(x_embed,encoder_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "98febd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = tokenizer.word_index[\"<sos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "238b27a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4554c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnnProject2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
