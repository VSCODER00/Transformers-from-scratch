{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ae3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c8d10464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 dimensions for each word\n",
    "import math\n",
    "def positionalEncodings(sequence):\n",
    "    \n",
    "    PE=[]\n",
    "    d_model=4\n",
    "    for pos in range(sequence):\n",
    "        EncodingsOfEach=[]\n",
    "        for i in range(d_model):\n",
    "            if i%2==0:\n",
    "                temp=pos/(math.pow(10000,(2*i)/d_model))\n",
    "                EncodingsOfEach.append(math.sin(temp))\n",
    "            else:\n",
    "                temp=pos/(math.pow(10000,(2*(i-1))/d_model))\n",
    "                EncodingsOfEach.append(math.cos(temp))\n",
    "        PE.append(EncodingsOfEach)\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "48fff696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def selfAttention(embeddings, W_q, W_k, W_v):\n",
    "#     batch_size = tf.shape(embeddings)[0]\n",
    "#     seq_len = tf.shape(embeddings)[1]\n",
    "\n",
    "#     batch_outputs = []\n",
    "\n",
    "#     for b in range(batch_size):\n",
    "#         x = embeddings[b]            # (seq_len, d_model)\n",
    "\n",
    "#         Q, K, V = [], [], []\n",
    "#         for i in range(seq_len):\n",
    "#             x_i = tf.expand_dims(x[i], 0)   # (1, d_model)\n",
    "#             Q.append(tf.matmul(x_i, W_q))\n",
    "#             K.append(tf.matmul(x_i, W_k))\n",
    "#             V.append(tf.matmul(x_i, W_v))\n",
    "\n",
    "#         d_k = tf.math.sqrt(tf.cast(tf.shape(K[0])[1], tf.float32))\n",
    "\n",
    "#         attention_outputs = []\n",
    "\n",
    "#         for i in range(seq_len):\n",
    "#             score_list = []\n",
    "#             for j in range(seq_len):\n",
    "#                 score = tf.matmul(Q[i], K[j], transpose_b=True)[0, 0] / d_k\n",
    "#                 score_list.append(score)\n",
    "\n",
    "#             scores = tf.stack(score_list)\n",
    "#             weights = tf.nn.softmax(scores)\n",
    "\n",
    "#             output = tf.zeros_like(V[0])\n",
    "#             for j in range(seq_len):\n",
    "#                 output += tf.expand_dims(weights[j], axis=0) * V[j]\n",
    "\n",
    "#             attention_outputs.append(output[0])\n",
    "\n",
    "#         batch_outputs.append(tf.stack(attention_outputs))  # (seq_len, d_model)\n",
    "\n",
    "#     return tf.stack(batch_outputs)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "def selfAttention(x, W_q, W_k, W_v):\n",
    "    \"\"\"\n",
    "    x: (batch_size, seq_len, d_model)\n",
    "    W_q, W_k, W_v: (d_model, d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    # Linear projections\n",
    "    Q = tf.matmul(x, W_q)  # (batch, seq_len, d_model)\n",
    "    K = tf.matmul(x, W_k)\n",
    "    V = tf.matmul(x, W_v)\n",
    "\n",
    "    d_k = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "\n",
    "    # Scaled dot-product attention\n",
    "    scores = tf.matmul(Q, K, transpose_b=True)  # (batch, seq_len, seq_len)\n",
    "    scores = scores / tf.math.sqrt(d_k)\n",
    "\n",
    "    weights = tf.nn.softmax(scores, axis=-1)    # (batch, seq_len, seq_len)\n",
    "\n",
    "    output = tf.matmul(weights, V)               # (batch, seq_len, d_model)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "adc88dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_and_normalize(output_of_previous,input_of_previous):\n",
    "    layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    return layer_norm(output_of_previous + input_of_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea40a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeedForwardNN(x, W1, b1, W2, b2):\n",
    "    hidden = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "    out = tf.matmul(hidden, W2) + b2\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8c5f8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(positional_encodings_plus_embeddings,W_q,W_k,W_v,W1,b1,W2,b2):\n",
    "    self_attn_output=selfAttention(positional_encodings_plus_embeddings,W_q,W_k,W_v)\n",
    "    add_and_normalize_1_output=Add_and_normalize(self_attn_output,positional_encodings_plus_embeddings)\n",
    "    ffn_output=FeedForwardNN(add_and_normalize_1_output,W1,b1,W2,b2)\n",
    "    encoder_output=Add_and_normalize(ffn_output,add_and_normalize_1_output)\n",
    "    return encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c708cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=tf.constant([[1,0,1,0],[0,1,0,1],[1,1,1,1]],dtype=tf.float32)\n",
    "positional_encodings=positionalEncodings(len(embeddings))\n",
    "embeddings_plus_PE=embeddings+positional_encodings\n",
    "d_model=embeddings_plus_PE[0].shape[0]\n",
    "encoder_params = []\n",
    "for _ in range(6):\n",
    "    params = {\n",
    "        \"W_q\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_k\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_v\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W1\": tf.Variable(tf.random.normal(shape=(d_model,256))),\n",
    "        \"b1\": tf.Variable(tf.random.normal(shape=(256,))),\n",
    "        \"W2\": tf.Variable(tf.random.normal(shape=(256,d_model))),\n",
    "        \"b2\": tf.Variable(tf.random.normal(shape=(d_model,)))\n",
    "    }\n",
    "    encoder_params.append(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4e386143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoderStack(x, encoder_params):\n",
    "    for layer in encoder_params:\n",
    "        x = Encoder(\n",
    "            x,\n",
    "            layer[\"W_q\"],\n",
    "            layer[\"W_k\"],\n",
    "            layer[\"W_v\"],\n",
    "            layer[\"W1\"],\n",
    "            layer[\"b1\"],\n",
    "            layer[\"W2\"],\n",
    "            layer[\"b2\"]\n",
    "        )\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1364aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output=(encoderStack(embeddings_plus_PE,encoder_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d25b8183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[-1.3913472 ,  0.6703489 , -0.46256405,  1.1835624 ],\n",
       "       [-1.3935652 ,  0.6702541 , -0.45905954,  1.1823704 ],\n",
       "       [-1.3927484 ,  0.67031825, -0.46036035,  1.1827906 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8df09",
   "metadata": {},
   "source": [
    "Decoder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a7cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_Attention(embeddings, W_q, W_k, W_v,mask):\n",
    "    numberOfWords = tf.shape(embeddings)[0]\n",
    "\n",
    "    Q, K, V = [], [], []\n",
    "    for i in range(numberOfWords):\n",
    "        x_i = tf.expand_dims(embeddings[i], 0)\n",
    "        Q.append(tf.matmul(x_i, W_q))\n",
    "        K.append(tf.matmul(x_i, W_k))\n",
    "        V.append(tf.matmul(x_i, W_v))\n",
    "\n",
    "    d_k = tf.math.sqrt(tf.cast(tf.shape(K[0])[1], tf.float32))\n",
    "\n",
    "    attention_outputs = []\n",
    "\n",
    "    for i in range(numberOfWords):\n",
    "        score_list = []\n",
    "        for j in range(numberOfWords):\n",
    "            score = tf.matmul(Q[i], K[j], transpose_b=True)[0, 0] / d_k\n",
    "            score=score+mask[i][j]\n",
    "            score_list.append(score)\n",
    "\n",
    "        scores = tf.stack(score_list)\n",
    "        weights = tf.nn.softmax(scores)\n",
    "\n",
    "        output = tf.zeros_like(V[0])\n",
    "        for j in range(numberOfWords):\n",
    "            output += weights[j] * V[j]\n",
    "\n",
    "        attention_outputs.append(output[0])\n",
    "\n",
    "    return tf.stack(attention_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c69282d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder_decoder_attention(encoder_output,prev_layer_output,W_q,W_k,W_v):\n",
    "    numberOfWords = tf.shape(encoder_output)[0]\n",
    "\n",
    "    Q, K, V = [], [], []\n",
    "    for i in range(numberOfWords):\n",
    "        q_i = tf.expand_dims(prev_layer_output[i], 0)\n",
    "        enc_i = tf.expand_dims(encoder_output[i], 0)\n",
    "        Q.append(tf.matmul(q_i, W_q))\n",
    "        K.append(tf.matmul(enc_i, W_k))\n",
    "        V.append(tf.matmul(enc_i, W_v))\n",
    "\n",
    "    d_k = tf.math.sqrt(tf.cast(tf.shape(K[0])[1], tf.float32))\n",
    "\n",
    "    attention_outputs = []\n",
    "\n",
    "    for i in range(numberOfWords):\n",
    "        score_list = []\n",
    "        for j in range(numberOfWords):\n",
    "            score = tf.matmul(Q[i], K[j], transpose_b=True)[0, 0] / d_k\n",
    "            score_list.append(score)\n",
    "\n",
    "        scores = tf.stack(score_list)\n",
    "        weights = tf.nn.softmax(scores)\n",
    "\n",
    "        output = tf.zeros_like(V[0])\n",
    "        for j in range(numberOfWords):\n",
    "            output += tf.expand_dims(weights[j], axis=0) * V[j]\n",
    "\n",
    "        attention_outputs.append(output[0])\n",
    "\n",
    "    return tf.stack(attention_outputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5130bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(positional_encodings_plus_embeddings,encoder_output,W_q_self,W_k_self,W_v_self,W_q_cross,W_k_cross,W_v_cross,mask,W1,b1,W2,b2):\n",
    "    masked_self_attn_output=masked_Attention(positional_encodings_plus_embeddings,W_q_self,W_k_self,W_v_self,mask)\n",
    "    add_and_normalize_1_output=Add_and_normalize(masked_self_attn_output,positional_encodings_plus_embeddings)\n",
    "    encoder_decoder_attn_output=Encoder_decoder_attention(encoder_output,add_and_normalize_1_output,W_q_cross,W_k_cross,W_v_cross)\n",
    "    add_and_normalize_2_output=Add_and_normalize(encoder_decoder_attn_output,add_and_normalize_1_output)\n",
    "    ffn_output=FeedForwardNN(add_and_normalize_2_output,W1,b1,W2,b2)\n",
    "    decoder_output=Add_and_normalize(ffn_output,add_and_normalize_2_output)\n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa646e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_mask(d):\n",
    "    mask = tf.linalg.band_part(tf.ones((d, d)), -1, 0)\n",
    "    return (1.0 - mask) * -1e9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0f5e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=embeddings_plus_PE[0].shape[0]\n",
    "mask=causal_mask(d_model)\n",
    "decoder_params = []\n",
    "\n",
    "for _ in range(6):\n",
    "    params = {\n",
    "        \"W_q_self\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_k_self\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_v_self\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_q_cross\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_k_cross\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_v_cross\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W1\": tf.Variable(tf.random.normal(shape=(d_model,256))),\n",
    "        \"b1\": tf.Variable(tf.random.normal(shape=(256,))),\n",
    "        \"W2\": tf.Variable(tf.random.normal(shape=(256,d_model))),\n",
    "        \"b2\": tf.Variable(tf.random.normal(shape=(d_model,)))\n",
    "    }\n",
    "    decoder_params.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd4c1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoderStack(x,decoder_params,encoder_output):\n",
    "    for layer in decoder_params:\n",
    "        x=decoder(x,encoder_output,layer[\"W_q_self\"],layer[\"W_k_self\"],layer[\"W_v_self\"],layer[\"W_q_cross\"],layer[\"W_k_cross\"],layer[\"W_v_cross\"],mask,layer[\"W1\"],layer[\"b1\"],layer[\"W2\"],layer[\"b2\"])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37d5e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=tf.constant([[1,0,1,0],[0,1,1,0],[1,1,0,1]],dtype=tf.float32)\n",
    "positional_encodings=positionalEncodings(len(embeddings))\n",
    "embeddings_plus_PE=embeddings+positional_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60110059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.83228827 -1.6974741   0.27196252  0.59322333]\n",
      " [ 0.8322718  -1.6974778   0.2719764   0.59322953]\n",
      " [ 0.8322394  -1.6974734   0.27192146  0.59331256]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(decoderStack(embeddings_plus_PE,decoder_params,encoder_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e5ea5",
   "metadata": {},
   "source": [
    "Preparing the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b07759c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "816d6504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>User Utterance</th>\n",
       "      <th>Bot Response</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Context/Session ID</th>\n",
       "      <th>Entities</th>\n",
       "      <th>User Feedback</th>\n",
       "      <th>Conversation Outcome</th>\n",
       "      <th>User Profile</th>\n",
       "      <th>Channel/Platform</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Emotion/Sentiment</th>\n",
       "      <th>Location</th>\n",
       "      <th>User Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uKqYhMMQ5S</td>\n",
       "      <td>Charge bar between follow student.</td>\n",
       "      <td>Important law into large example range. Player...</td>\n",
       "      <td>2023-10-31 18:02:06</td>\n",
       "      <td>4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4</td>\n",
       "      <td>event</td>\n",
       "      <td>negative</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>Annette Henderson</td>\n",
       "      <td>social media</td>\n",
       "      <td>German</td>\n",
       "      <td>confused</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>returning customers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID                      User Utterance  \\\n",
       "0  uKqYhMMQ5S  Charge bar between follow student.   \n",
       "\n",
       "                                        Bot Response            Timestamp  \\\n",
       "0  Important law into large example range. Player...  2023-10-31 18:02:06   \n",
       "\n",
       "                     Context/Session ID Entities User Feedback  \\\n",
       "0  4dfe56dc-efe2-49c6-be9f-ce5b84ca4de4    event      negative   \n",
       "\n",
       "  Conversation Outcome       User Profile Channel/Platform Language  \\\n",
       "0           incomplete  Annette Henderson     social media   German   \n",
       "\n",
       "  User Emotion/Sentiment Location         User Segment  \n",
       "0               confused   Sydney  returning customers  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('chatbot_dataset.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "36fd360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['User Utterance']\n",
    "y=df['Bot Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e2fc27da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Charge bar between follow student.\n",
       "1               Bad every reflect huge contain.\n",
       "2       Glass remember many dog director under.\n",
       "3           Help charge record many talk tough.\n",
       "4               Position not man much material.\n",
       "                         ...                   \n",
       "9995           How major might home gun reduce.\n",
       "9996          Result executive some commercial.\n",
       "9997                Require week affect factor.\n",
       "9998                    Film I green like song.\n",
       "9999                   Wonder majority million.\n",
       "Name: User Utterance, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "39a405b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(temp):\n",
    "    temp=temp.lower()\n",
    "    temp=temp.replace(\".\",\"\")\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "631211b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.apply(clean_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bae82fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            charge bar between follow student\n",
       "1               bad every reflect huge contain\n",
       "2       glass remember many dog director under\n",
       "3           help charge record many talk tough\n",
       "4               position not man much material\n",
       "                         ...                  \n",
       "9995           how major might home gun reduce\n",
       "9996          result executive some commercial\n",
       "9997                require week affect factor\n",
       "9998                    film i green like song\n",
       "9999                   wonder majority million\n",
       "Name: User Utterance, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2bcbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6d891ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input=\"<sos> \"+y\n",
    "y_target=y+\" <eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f36bdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4b623bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(filters='',oov_token=\"OOV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "24f088eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(x)+list(y_input)+list(y_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bbfc5de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33baaa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tokenizer.texts_to_sequences(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5e6e99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input=tokenizer.texts_to_sequences(y_input)\n",
    "y_target=tokenizer.texts_to_sequences(y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fcf3c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "x=pad_sequences(x,padding='post')\n",
    "y_input=pad_sequences(y_input,padding='post')\n",
    "y_target=pad_sequences(y_target,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4c57e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfWords=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3410603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=numberOfWords,\n",
    "    output_dim=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9cfb8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=embedding_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3543748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input=embedding_layer(y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ac27a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target=embedding_layer(y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "50863760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 dimensions for each word\n",
    "import math\n",
    "def positionalEncodings(sequence):\n",
    "    \n",
    "    PE=[]\n",
    "    d_model=64\n",
    "    for pos in range(sequence):\n",
    "        EncodingsOfEach=[]\n",
    "        for i in range(d_model):\n",
    "            if i%2==0:\n",
    "                temp=pos/(math.pow(10000,(2*i)/d_model))\n",
    "                EncodingsOfEach.append(math.sin(temp))\n",
    "            else:\n",
    "                temp=pos/(math.pow(10000,(2*(i-1))/d_model))\n",
    "                EncodingsOfEach.append(math.cos(temp))\n",
    "        PE.append(EncodingsOfEach)\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f929b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PE=positionalEncodings(len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "898e13e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x+PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "00d38976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1a77035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 10, 64])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f6806228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_model=x[0].shape[1]\n",
    "encoder_params = []\n",
    "for _ in range(6):\n",
    "    params = {\n",
    "        \"W_q\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_k\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W_v\": tf.Variable(tf.random.normal(shape=(d_model,d_model))),\n",
    "        \"W1\": tf.Variable(tf.random.normal(shape=(d_model,256))),\n",
    "        \"b1\": tf.Variable(tf.random.normal(shape=(256,))),\n",
    "        \"W2\": tf.Variable(tf.random.normal(shape=(256,d_model))),\n",
    "        \"b2\": tf.Variable(tf.random.normal(shape=(d_model,)))\n",
    "    }\n",
    "    encoder_params.append(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0715889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-3.0989262e-01  1.4312212e+00 -1.1284838e+00 ... -2.3945420e+00\n",
      "    2.2073835e-03  1.1830878e+00]\n",
      "  [-3.0989212e-01  1.4312230e+00 -1.1284851e+00 ... -2.3945439e+00\n",
      "    2.2078454e-03  1.1830875e+00]\n",
      "  [-3.0989325e-01  1.4312245e+00 -1.1284866e+00 ... -2.3945451e+00\n",
      "    2.2089034e-03  1.1830881e+00]\n",
      "  ...\n",
      "  [-3.0989361e-01  1.4312220e+00 -1.1284819e+00 ... -2.3945410e+00\n",
      "    2.2056103e-03  1.1830901e+00]\n",
      "  [-3.0989277e-01  1.4312241e+00 -1.1284810e+00 ... -2.3945405e+00\n",
      "    2.2068322e-03  1.1830887e+00]\n",
      "  [-3.0989277e-01  1.4312255e+00 -1.1284813e+00 ... -2.3945410e+00\n",
      "    2.2076964e-03  1.1830879e+00]]\n",
      "\n",
      " [[-3.5908791e-01  1.3894553e+00 -1.0837812e+00 ... -2.4052894e+00\n",
      "    1.3856903e-02  1.2016587e+00]\n",
      "  [-3.5908574e-01  1.3894622e+00 -1.0837830e+00 ... -2.4052908e+00\n",
      "    1.3856605e-02  1.2016572e+00]\n",
      "  [-3.5908735e-01  1.3894629e+00 -1.0837842e+00 ... -2.4052920e+00\n",
      "    1.3856620e-02  1.2016555e+00]\n",
      "  ...\n",
      "  [-3.5908723e-01  1.3894600e+00 -1.0837811e+00 ... -2.4052896e+00\n",
      "    1.3854831e-02  1.2016594e+00]\n",
      "  [-3.5908639e-01  1.3894628e+00 -1.0837805e+00 ... -2.4052899e+00\n",
      "    1.3855308e-02  1.2016586e+00]\n",
      "  [-3.5908669e-01  1.3894650e+00 -1.0837801e+00 ... -2.4052894e+00\n",
      "    1.3855770e-02  1.2016568e+00]]\n",
      "\n",
      " [[-1.6077073e-01  1.4036212e+00 -1.2448639e+00 ... -2.2891314e+00\n",
      "   -5.2065402e-03  1.0131929e+00]\n",
      "  [-1.6076487e-01  1.4036252e+00 -1.2448709e+00 ... -2.2891238e+00\n",
      "   -5.2120090e-03  1.0132004e+00]\n",
      "  [-1.6076548e-01  1.4036260e+00 -1.2448716e+00 ... -2.2891207e+00\n",
      "   -5.2114874e-03  1.0132022e+00]\n",
      "  ...\n",
      "  [-1.6076575e-01  1.4036225e+00 -1.2448684e+00 ... -2.2891207e+00\n",
      "   -5.2127838e-03  1.0132078e+00]\n",
      "  [-1.6076286e-01  1.4036272e+00 -1.2448722e+00 ... -2.2891150e+00\n",
      "   -5.2136183e-03  1.0132077e+00]\n",
      "  [-1.6076635e-01  1.4036280e+00 -1.2448702e+00 ... -2.2891152e+00\n",
      "   -5.2122325e-03  1.0132067e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.2412446e-01  1.3890746e+00 -1.1175184e+00 ... -2.4067414e+00\n",
      "    2.4425492e-02  1.1634836e+00]\n",
      "  [-3.2412213e-01  1.3890833e+00 -1.1175190e+00 ... -2.4067402e+00\n",
      "    2.4424419e-02  1.1634805e+00]\n",
      "  [-3.2412404e-01  1.3890849e+00 -1.1175183e+00 ... -2.4067411e+00\n",
      "    2.4425790e-02  1.1634802e+00]\n",
      "  ...\n",
      "  [-3.2412428e-01  1.3890799e+00 -1.1175165e+00 ... -2.4067388e+00\n",
      "    2.4423316e-02  1.1634831e+00]\n",
      "  [-3.2412326e-01  1.3890836e+00 -1.1175146e+00 ... -2.4067369e+00\n",
      "    2.4424493e-02  1.1634818e+00]\n",
      "  [-3.2412866e-01  1.3890845e+00 -1.1175083e+00 ... -2.4067345e+00\n",
      "    2.4426505e-02  1.1634808e+00]]\n",
      "\n",
      " [[-3.3974424e-01  1.3592657e+00 -1.1689311e+00 ... -2.4666915e+00\n",
      "    2.4615347e-02  1.1656994e+00]\n",
      "  [-3.3974397e-01  1.3592665e+00 -1.1689324e+00 ... -2.4666922e+00\n",
      "    2.4616048e-02  1.1656988e+00]\n",
      "  [-3.3974442e-01  1.3592672e+00 -1.1689342e+00 ... -2.4666934e+00\n",
      "    2.4616659e-02  1.1656986e+00]\n",
      "  ...\n",
      "  [-3.3974689e-01  1.3592653e+00 -1.1689299e+00 ... -2.4666913e+00\n",
      "    2.4614081e-02  1.1657016e+00]\n",
      "  [-3.3974630e-01  1.3592665e+00 -1.1689286e+00 ... -2.4666898e+00\n",
      "    2.4614960e-02  1.1657008e+00]\n",
      "  [-3.3974630e-01  1.3592687e+00 -1.1689279e+00 ... -2.4666886e+00\n",
      "    2.4615213e-02  1.1656997e+00]]\n",
      "\n",
      " [[-2.8218445e-01  1.4291431e+00 -1.1395788e+00 ... -2.3432608e+00\n",
      "    2.4851710e-03  1.2134409e+00]\n",
      "  [-2.8218174e-01  1.4291494e+00 -1.1395804e+00 ... -2.3432610e+00\n",
      "    2.4837852e-03  1.2134377e+00]\n",
      "  [-2.8218263e-01  1.4291509e+00 -1.1395810e+00 ... -2.3432622e+00\n",
      "    2.4845451e-03  1.2134371e+00]\n",
      "  ...\n",
      "  [-2.8218329e-01  1.4291478e+00 -1.1395770e+00 ... -2.3432596e+00\n",
      "    2.4825186e-03  1.2134403e+00]\n",
      "  [-2.8218251e-01  1.4291512e+00 -1.1395758e+00 ... -2.3432586e+00\n",
      "    2.4833381e-03  1.2134386e+00]\n",
      "  [-2.8218293e-01  1.4291525e+00 -1.1395755e+00 ... -2.3432581e+00\n",
      "    2.4840236e-03  1.2134373e+00]]], shape=(10000, 10, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(encoderStack(x,encoder_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2183e48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnnProject2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
